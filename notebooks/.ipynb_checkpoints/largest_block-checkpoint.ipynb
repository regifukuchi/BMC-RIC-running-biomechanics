{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b12e57ac",
   "metadata": {},
   "source": [
    "# Translate Matlab function into Python\n",
    "\n",
    "Reginaldo K Fukuchi \n",
    "\n",
    "This NB implements the \"gait_steps.m\" Sean Osis method to detect gait events."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f4e9cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare environment\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import os, sys\n",
    "sys.path.insert(1, r'../functions')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2680f6f1-f95c-46e8-941b-bbfba6cd2cf9",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Begin translating LARGEST_BLOCK.m to Python\n",
    "* Tried to translate Matlab function into Python function using SMOP but it didn't help much\n",
    "https://github.com/regifukuchi/smophttps://github.com/regifukuchi/smop\n",
    "* Also tried to use Github Copilot but it didn't help much either\n",
    "\n",
    "## Portion of gait_steps.py prior invoking largest_block.m Matlab function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c426f0ce-b789-4af1-ac69-cafaba8cfa8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# File directories \n",
    "dir_data = r'../data' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5666dcf3-acf3-4fde-ac8e-35e4a6dafd79",
   "metadata": {},
   "outputs": [],
   "source": [
    "info_both = pd.read_csv(os.path.join(dir_data, 'info_both.csv'), \n",
    "                        usecols=['sub_id','filename','speed','Age','Height','Mass','group'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be0c484d-696f-4a3c-b6d7-c57bdb701291",
   "metadata": {},
   "outputs": [],
   "source": [
    "import parse_gait_kinematics as parse_gait\n",
    "import SCS_RIC as scs\n",
    "import jointangles3d as jang3d\n",
    "from gait_kinematics import gait_kinematics\n",
    "from gait_steps import gait_steps\n",
    "from gait3d_angles import gait3d_angles\n",
    "from critic_damp import critic_damp\n",
    "from svdt import svdt\n",
    "from tnorma import tnorma\n",
    "from detecta import detect_peaks\n",
    "from pca_td import pca_td\n",
    "from pca_to import pca_to\n",
    "from largest_block import largest_block\n",
    "\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "import scipy.io as spio\n",
    "from scipy.signal import butter, filtfilt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0792dc6-4250-4e9a-91b6-402c8c3604fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_ids = info_both[info_both['group']=='RIC']['sub_id'].tolist()\n",
    "fn_RIC  = info_both[info_both['group']=='RIC']['filename'].tolist()\n",
    "RIC_dir = r'C:\\Users\\Reginaldo\\OneDrive - University of Calgary\\data\\Figshare_SciData\\new_unzip'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "676cc077-5c2e-4251-9ab1-91e7ce2eaa13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running Injury Clinic data set\n",
    "fn_json=os.path.join(RIC_dir, str(sub_ids[5]), fn_RIC[5])\n",
    "neutral, joints, gait, hz = parse_gait.parse_RIC(fn_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4305e90-9bf0-4bb3-b3fc-2ba093bd9de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate joint angles\n",
    "virt_mkrs, angles = gait3d_angles(neutral, joints, gait)\n",
    "\n",
    "# Convert dict in arrays\n",
    "L_ankle_ang, R_ankle_ang = angles['L_ankle_ang'], angles['R_ankle_ang']\n",
    "L_knee_ang, R_knee_ang = angles['L_knee_ang'], angles['R_knee_ang']\n",
    "L_hip_ang, R_hip_ang = angles['L_hip_ang'], angles['R_hip_ang']\n",
    "L_foot_ang, R_foot_ang = angles['L_foot_ang'], angles['R_foot_ang']\n",
    "pelvis_ang = angles['pelvis_ang']\n",
    "\n",
    "# Convert angles in degrees\n",
    "L_ankle_ang, R_ankle_ang = L_ankle_ang * (180/np.pi), R_ankle_ang * (180/np.pi)\n",
    "L_knee_ang, R_knee_ang = L_knee_ang * (180/np.pi), R_knee_ang * (180/np.pi)\n",
    "L_hip_ang, R_hip_ang = L_hip_ang * (180/np.pi), R_hip_ang * (180/np.pi)\n",
    "L_foot_ang, R_foot_ang = L_foot_ang * (180/np.pi), R_foot_ang * (180/np.pi)\n",
    "pelvis_ang = pelvis_ang * (180/np.pi)\n",
    "\n",
    "# Structure the data to be input into gait_steps\n",
    "joints_lbls = ['pelvis','L_foot','R_foot','L_hip','R_hip','L_knee','R_knee',\n",
    "               'L_ankle','R_ankle']\n",
    "xyz = list('XYZ')*len(joints_lbls)\n",
    "joints_lbls = [ele for ele in joints_lbls for i in range(3)]\n",
    "joints_lbls = [joints_lbls[i]+'_'+xyz[i] for i in range(len(xyz))]\n",
    "\n",
    "# Create a pandas df with angles\n",
    "angs = np.hstack([pelvis_ang, L_foot_ang, R_foot_ang, \n",
    "                  L_hip_ang, R_hip_ang, L_knee_ang, R_knee_ang, \n",
    "                  L_ankle_ang, R_ankle_ang])\n",
    "angles = pd.DataFrame(data=angs, columns=joints_lbls)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5ed7052-a9a7-4f85-9c33-1eb40c8111d1",
   "metadata": {},
   "source": [
    "## Test gait_step.py with largest_block.py function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "066776e6-c70a-4622-801b-c072656f636a",
   "metadata": {},
   "outputs": [],
   "source": [
    "L_TD_RIC, L_TO_RIC, R_TD_RIC, R_TO_RIC, eventsflag_RIC, label_RIC = gait_steps(neutral, gait, angles, hz)\n",
    "RTD_RIC, RTO_RIC = R_TD_RIC.astype(int).tolist(), R_TO_RIC.astype(int).tolist()\n",
    "LTD_RIC, LTO_RIC = L_TD_RIC.astype(int).tolist(), L_TO_RIC.astype(int).tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c0520b3-a109-4c2c-9618-44ecd565e5ff",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Test LARGEST_BLOCK.py function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "911b514f-10b6-4ada-a2f3-ed9bcbb2cffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "FFi = [119, 249, 379, 511, 641, 771, 902, 1031, 1162, 1292, 1422, 1553, 1683, \n",
    "       1812, 1943, 2075, 2205, 2336, 2466, 2597, 2729, 2859, 2990, 3120, 3249, \n",
    "       3379, 3510, 3640, 3770, 3901, 4031, 4162, 4291, 4420, 4549, 4680, 4809, 4938]\n",
    "FBi = [185, 314, 436, 577, 707, 837, 967, 1097, 1229, 1358, 1489, 1619, 1745, \n",
    "       1877, 2009, 2142, 2263, 2401, 2523, 2664, 2794, 2925, 3056, 3186, 3314, \n",
    "       3445, 3574, 3705, 3836, 3966, 4096, 4226, 4356, 4485, 4616, 4746, 4873]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df01b00e-f26f-40f5-927c-dbb47ed8a684",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "FFi_mod, FBi_mod, block_start, block_end = largest_block(FFi, FBi)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66e44b5a-6f0e-4037-9271-ad845b5e1df7",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Call Matlab function LARGEST_BLOCK.m from Python\n",
    "\n",
    "Call Matlab from Python\n",
    "https://towardsdatascience.com/matlab-function-in-python-739c473c8176"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a19efce-3280-4f0b-9157-69f8c6a37d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matlab\n",
    "import matlab.engine\n",
    "eng = matlab.engine.start_matlab()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55dd93aa-509c-4826-b1fb-0ac4956eebd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_funct = r'../functions'\n",
    "eng.cd(path_funct, nargout=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3623b653-a3c1-493f-bbc2-a91694eed23b",
   "metadata": {},
   "outputs": [],
   "source": [
    "L_FFi, L_FBi, L_block_start, L_block_end = eng.largest_block(matlab.double(list(FFi)), \n",
    "                                                             matlab.double(list(FBi)), nargout=4)\n",
    "\n",
    "L_FFi = np.array(L_FFi).flatten().astype(int)\n",
    "L_FBi = np.array(L_FBi).flatten().astype(int)\n",
    "\n",
    "if (L_FFi.shape[0] < 2) or (L_FBi.shape[0] < 2):\n",
    "    print('Automated event detection unable to pull adequate number of strides for analysis. Please redo your data collection.')\n",
    "    sys.exit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "773b2475-a9d0-496a-a0b0-72ad7b84c9f3",
   "metadata": {},
   "source": [
    "Compare outputs between Matlab and Python functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b12af44-81cb-42d5-bb72-21ad5d139e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FFi\n",
    "np.array_equal(FFi_mod,L_FFi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "681db82e-ff38-4420-9307-1fb5f75cbe27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FBi\n",
    "np.array_equal(FBi_mod,L_FBi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d88696d9-78a7-4e6b-80ea-1d1b70aa2865",
   "metadata": {},
   "outputs": [],
   "source": [
    "block_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d01f76f-a844-454c-b43c-f4c92c14f38c",
   "metadata": {},
   "outputs": [],
   "source": [
    "L_block_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54b81af7-3991-4359-9caa-a91633503530",
   "metadata": {},
   "outputs": [],
   "source": [
    "block_end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2812db4-d1da-472a-9a59-c91c2570ae29",
   "metadata": {},
   "outputs": [],
   "source": [
    "L_block_end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fa4d897-383c-45ae-8316-33c80ca2eb90",
   "metadata": {},
   "source": [
    "## Function largest_block.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3fc57c1-e207-4aec-bd9d-5fdccedcd6c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine and sort the FF and FB\n",
    "allsort = np.vstack((np.array([FFi,np.zeros(len(FFi))]).T,np.array([FBi,np.ones(len(FBi))]).T))\n",
    "inds = np.argsort(allsort[:,0])\n",
    "allsort = allsort[inds,:].astype(int)\n",
    "\n",
    "# Remove trailing FF\n",
    "while allsort[-1,1] != 1:\n",
    "    allsort = allsort[:-1,:]\n",
    "    \n",
    "allsort_bak = allsort\n",
    "\n",
    "i=-1\n",
    "skip = -1\n",
    "longest_length =[]\n",
    "\n",
    "# series of while loops will search for longest continuous chunk of data\n",
    "#first while loop adds up the length of a continuous segments adding in the\n",
    "#indicies that are skipped (because they contain the dicontinuity)\n",
    "while (np.sum(longest_length)+skip < allsort_bak.shape[0]) and allsort.shape[0]>1:\n",
    "\n",
    "    # points, in case of two 1s run below\n",
    "    idx_skip = -1\n",
    "    k = 0\n",
    "\n",
    "    # allsort must start with a 0\n",
    "    while allsort[0,1] == 1:\n",
    "        allsort = allsort[1:,:]\n",
    "        #skip is an overall counter for the main while loop in conjuction with longest_length\n",
    "        skip = skip + 1\n",
    "\n",
    "        # idx_skip keeps track of when values are skipped for the purpose of indexing\n",
    "        idx_skip = idx_skip + 1\n",
    "\n",
    "        # remove discontinuities occuring at the start of allsort\n",
    "        while (allsort[k,1]==allsort[k+1,1]) and (k+1<allsort.shape[0]):\n",
    "            allsort = allsort[k+2:,:]\n",
    "            skip = skip + 2\n",
    "            idx_skip = idx_skip + 2\n",
    "\n",
    "    k = 2\n",
    "    while k<=len(allsort) and allsort[0:k:2,1].mean()==0 and allsort[1:k:2,1].mean()==1:\n",
    "        k = k + 2\n",
    "\n",
    "    i = i+1\n",
    "\n",
    "    # we don't want to use a possibly erroneous point in the data and we\n",
    "    # must end the sequence on a 1, so when the dicontinuity occurs with two\n",
    "    # 1s in a row, we must roll back by 2\n",
    "\n",
    "    if (allsort.shape[0] > k) and (k > 2):\n",
    "        if (allsort[k-2,1]==1) and (allsort[k-3,1]==1):\n",
    "            allsort = allsort[:k-5,:]\n",
    "        else:\n",
    "            allsort = allsort[:k-3,:]\n",
    "\n",
    "    #for the special case where there are two discontinuities of 0s in a row\n",
    "    index = np.empty(shape=(2,allsort_bak.shape[0])) * np.NaN\n",
    "    if k==2 and allsort[0,1]==0:\n",
    "        allsort = allsort[2:,:]\n",
    "        longest_length.append(0)\n",
    "\n",
    "        # we want to index one passed the discontinuity\n",
    "        if i==0:\n",
    "            # if this occurs for the first index, only includes values skipped\n",
    "            index[0,0] = idx_skip\n",
    "            index[1,0] = idx_skip\n",
    "        else:\n",
    "            index[0,i] = index[1,i-1] + indx_skip+1\n",
    "            index[1,i] = index[1,i-1] + indx_skip+1\n",
    "\n",
    "        skip = skip + 2\n",
    "\n",
    "    else:\n",
    "        # otherwise count as normal\n",
    "        longest_length.append(allsort.shape[0])\n",
    "\n",
    "        # create ordered index of where continuous chunks occur\n",
    "        if i==0:\n",
    "            index[0,0] = 1 + idx_skip\n",
    "            index[1,0] = longest_length[i] + idx_skip\n",
    "        else:\n",
    "            index[1,i] = index[1,i-1]+3+idx_skip\n",
    "\n",
    "            # Longest_length can only be 0 when two discontinuities of 1s happen in a row, \n",
    "            #below accounts that the index end needs to still progress by 1 (but longest_length\n",
    "            #still needs to be 0 for the main counter)\n",
    "            if longest_length[i] > 0:\n",
    "                index[1,i] = index[0,i]+longest_length[i]-1\n",
    "            else:\n",
    "                index[1,i] = index[0,i]+longest_length[i]\n",
    "\n",
    "        #reset allsort for next loop iteration to be passed the discontinuity\n",
    "        index = index[~np.isnan(index)].reshape((2,-1))\n",
    "        allsort = allsort_bak[index[1,i].astype(int)+3:,:]\n",
    "\n",
    "        #however we want to skip passed the discontinuity to the next footfall.\n",
    "        #This entails skipping the discontinuity (for example if the\n",
    "        #discontinuity is two FF, we skip over these two values\n",
    "        skip = skip + 2\n",
    "        \n",
    "#determine which index has the largest continuous block\n",
    "longest_index = np.argmax(np.diff(index, axis=0))\n",
    "\n",
    "# reorder allsort to contain only this block\n",
    "allsort_longest = allsort_bak[int(index[0,longest_index]):int(index[1,longest_index]+1),:]\n",
    "allsort = allsort_longest\n",
    "\n",
    "# Break back into components\n",
    "FFi_mod = allsort[allsort[:,1]==0,0]\n",
    "FBi_mod = allsort[allsort[:,1]==1,0]\n",
    "\n",
    "# want to track frame numbers of when the block on continuous data starts\n",
    "#and ends\n",
    "block_start = FFi_mod[0]\n",
    "block_end   = FBi_mod[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46bb950a-71da-4b83-8456-6dbe0d7f1e04",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "747867f1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
