{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b12e57ac",
   "metadata": {},
   "source": [
    "# Gait steps\n",
    "\n",
    "Reginaldo K Fukuchi \n",
    "\n",
    "This NB implements the \"gait_steps.m\" Sean Osis method to detect gait events."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f4e9cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare environment\n",
    "import os, glob, sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import signal\n",
    "import scipy.io as spio\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "from detecta import detect_peaks\n",
    "\n",
    "import sys\n",
    "sys.path.insert(1, r'../functions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a83576f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data\n",
    "pathname = r'../data'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23d21fe2-af84-4172-9bb3-7bf8ff196d2c",
   "metadata": {},
   "source": [
    "### Supporting functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3a772a5a-daba-4bb4-8bb0-cdd7c6ff17f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f7(seq):\n",
    "    seen = set()\n",
    "    seen_add = seen.add\n",
    "    return [x for x in seq if not (x in seen or seen_add(x))]\n",
    "\n",
    "def loadjson(filename):\n",
    "    import json # import library\n",
    "    with open(fn_json, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    return data\n",
    "\n",
    "def loadmat(filename):\n",
    "    '''\n",
    "    this function should be called instead of direct spio.loadmat\n",
    "    as it cures the problem of not properly recovering python dictionaries\n",
    "    from mat files. It calls the function check keys to cure all entries\n",
    "    which are still mat-objects\n",
    "    '''\n",
    "    import scipy.io as spio\n",
    "    \n",
    "    def _check_keys(d):\n",
    "        '''\n",
    "        checks if entries in dictionary are mat-objects. If yes\n",
    "        todict is called to change them to nested dictionaries\n",
    "        '''\n",
    "        for key in d:\n",
    "            if isinstance(d[key], spio.matlab.mat_struct):\n",
    "                d[key] = _todict(d[key])\n",
    "        return d\n",
    "\n",
    "    def _todict(matobj):\n",
    "        '''\n",
    "        A recursive function which constructs from matobjects nested dictionaries\n",
    "        '''\n",
    "        d = {}\n",
    "        for strg in matobj._fieldnames:\n",
    "            elem = matobj.__dict__[strg]\n",
    "            if isinstance(elem, spio.matlab.mat_struct):\n",
    "                d[strg] = _todict(elem)\n",
    "            elif isinstance(elem, np.ndarray):\n",
    "                d[strg] = _tolist(elem)\n",
    "            else:\n",
    "                d[strg] = elem\n",
    "        return d\n",
    "\n",
    "    def _tolist(ndarray):\n",
    "        '''\n",
    "        A recursive function which constructs lists from cellarrays\n",
    "        (which are loaded as numpy ndarrays), recursing into the elements\n",
    "        if they contain matobjects.\n",
    "        '''\n",
    "        elem_list = []\n",
    "        for sub_elem in ndarray:\n",
    "            if isinstance(sub_elem, spio.matlab.mat_struct):\n",
    "                elem_list.append(_todict(sub_elem))\n",
    "            elif isinstance(sub_elem, np.ndarray):\n",
    "                elem_list.append(_tolist(sub_elem))\n",
    "            else:\n",
    "                elem_list.append(sub_elem)\n",
    "        return elem_list\n",
    "    data = spio.loadmat(filename, struct_as_record=False, squeeze_me=True)\n",
    "    return _check_keys(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a40dae9",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Import data\n",
    "### RIC data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f6193729-bf7e-4aa4-8236-a8783ecb1409",
   "metadata": {},
   "outputs": [],
   "source": [
    "figshare_dir = r'C:\\Users\\Reginaldo\\OneDrive - University of Calgary\\data\\Figshare_SciData\\new_unzip'\n",
    "data_dir = r'../data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1cfd44f6-bcc9-45be-91cd-f9dd09d4dd13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['hz_w', 'hz_r', 'walking', 'running', 'joints', 'neutral', 'dv_w', 'dv_r'])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fn_json=os.path.join(figshare_dir, '201225', '20140515T133244.json')\n",
    "data_RIC = loadjson(fn_json)\n",
    "data_RIC.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "afe27f21-3698-4a59-91c6-6cdbb49282ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataframe column corresponding to the dataset\n",
    "neutral_lbls = list(data_RIC['neutral'].keys())\n",
    "xyz = list('XYZ')*len(neutral_lbls)\n",
    "neutral_lbls = [ele for ele in neutral_lbls for i in range(3)]\n",
    "neutral_lbls = [neutral_lbls[i]+'_'+xyz[i] for i in range(len(xyz))]\n",
    "\n",
    "# Joint marker labels static trial\n",
    "joints_lbls = list(data_RIC['joints'].keys())\n",
    "xyz = list('XYZ')*len(joints_lbls)\n",
    "joints_lbls = [ele for ele in joints_lbls for i in range(3)]\n",
    "joints_lbls = [joints_lbls[i]+'_'+xyz[i] for i in range(len(xyz))]\n",
    "\n",
    "# Marker labels running trial\n",
    "gait_lbls = list(data_RIC['running'].keys())\n",
    "xyz = list('XYZ')*len(gait_lbls)\n",
    "gait_lbls = [ele for ele in gait_lbls for i in range(3)]\n",
    "gait_lbls = [gait_lbls[i]+'_'+xyz[i] for i in range(len(xyz))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c53f476b-6e8b-45bf-816e-1f50f9dcc734",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert dictionaries into pandas dfs\n",
    "neutral = pd.DataFrame.from_dict(data_RIC['neutral']).values.reshape((1,len(neutral_lbls)),\n",
    "                                                                     order='F')\n",
    "joints  = pd.DataFrame.from_dict(data_RIC['joints']).values.reshape((1,len(joints_lbls)),\n",
    "                                                                     order='F')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d7925842-36e2-460b-b32f-2631373decde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert dictionaries into pandas dfs\n",
    "neutral = pd.DataFrame(data=neutral, \n",
    "                           columns=neutral_lbls)\n",
    "joints = pd.DataFrame(data=joints, \n",
    "                           columns=joints_lbls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7a2cafee-f4c7-4027-ae8d-18d88f0e603a",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_data = np.empty(shape=(5000, len(list(data_RIC['running'].keys()))*3))\n",
    "for m, mkr in enumerate(list(data_RIC['running'].keys())):\n",
    "    run_data[:, 3*m:3*(m+1)] = np.array(data_RIC['running'][mkr])\n",
    "# Create dataframe with running data\n",
    "gait = pd.DataFrame(data = run_data, columns=gait_lbls)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdb4d797-cbf5-4a27-be9f-1b84c2dcca94",
   "metadata": {},
   "source": [
    "### Run gait_kinematics.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fa1732fc-7a70-4a6c-8af4-ed4aacf36673",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gait_kinematics import gait_kinematics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "28ada83b-2668-4cb2-93b2-d5ca662e1d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Invoking function to calculate angles\n",
    "angle_L_ankle, angle_R_ankle, angle_L_knee, angle_R_knee, angle_L_hip, angle_R_hip, angle_L_foot, angle_R_foot, angle_Pelvis = gait_kinematics(joints, neutral, gait, data_RIC['hz_r'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f823acc3-59d9-4e31-ae82-15914325c2aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "angle_L_ankle, angle_R_ankle = angle_L_ankle*(180/np.pi), angle_R_ankle*(180/np.pi)\n",
    "angle_L_knee, angle_R_knee   = angle_L_knee*(180/np.pi), angle_R_knee*(180/np.pi)\n",
    "angle_L_hip, angle_R_hip     = angle_L_hip*(180/np.pi), angle_R_hip*(180/np.pi)\n",
    "angle_L_foot, angle_R_foot   = angle_L_foot*(180/np.pi), angle_R_foot*(180/np.pi)\n",
    "angle_Pelvis  = angle_Pelvis * (180/np.pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "46c552f8-dc3a-4ecb-8d20-f566e31e822e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataframe column corresponding to the dataset\n",
    "joints_lbls = ['pelvis','L_foot','R_foot','L_hip','R_hip','L_knee','R_knee',\n",
    "               'L_ankle','R_ankle']\n",
    "xyz = list('XYZ')*len(joints_lbls)\n",
    "joints_lbls = [ele for ele in joints_lbls for i in range(3)]\n",
    "joints_lbls = [joints_lbls[i]+'_'+xyz[i] for i in range(len(xyz))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ab57238e-3031-46c6-b4ef-642542320dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "angs = np.hstack([angle_Pelvis, angle_L_foot, angle_R_foot, \n",
    "                  angle_L_hip, angle_R_hip, angle_L_knee, angle_R_knee, \n",
    "                  angle_L_ankle, angle_R_ankle])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e40042da-4401-4fe9-93f2-2c404b778353",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pelvis_X</th>\n",
       "      <th>pelvis_Y</th>\n",
       "      <th>pelvis_Z</th>\n",
       "      <th>L_foot_X</th>\n",
       "      <th>L_foot_Y</th>\n",
       "      <th>L_foot_Z</th>\n",
       "      <th>R_foot_X</th>\n",
       "      <th>R_foot_Y</th>\n",
       "      <th>R_foot_Z</th>\n",
       "      <th>L_hip_X</th>\n",
       "      <th>...</th>\n",
       "      <th>L_knee_Z</th>\n",
       "      <th>R_knee_X</th>\n",
       "      <th>R_knee_Y</th>\n",
       "      <th>R_knee_Z</th>\n",
       "      <th>L_ankle_X</th>\n",
       "      <th>L_ankle_Y</th>\n",
       "      <th>L_ankle_Z</th>\n",
       "      <th>R_ankle_X</th>\n",
       "      <th>R_ankle_Y</th>\n",
       "      <th>R_ankle_Z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.130881</td>\n",
       "      <td>3.623830</td>\n",
       "      <td>-0.354510</td>\n",
       "      <td>2.983322</td>\n",
       "      <td>6.958619</td>\n",
       "      <td>-1.709532</td>\n",
       "      <td>12.427321</td>\n",
       "      <td>3.441102</td>\n",
       "      <td>-87.858121</td>\n",
       "      <td>0.986488</td>\n",
       "      <td>...</td>\n",
       "      <td>25.058309</td>\n",
       "      <td>19.450638</td>\n",
       "      <td>16.619757</td>\n",
       "      <td>51.327518</td>\n",
       "      <td>-6.431359</td>\n",
       "      <td>5.258269</td>\n",
       "      <td>-3.270496</td>\n",
       "      <td>-10.925609</td>\n",
       "      <td>-7.332781</td>\n",
       "      <td>26.055983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.109653</td>\n",
       "      <td>3.092453</td>\n",
       "      <td>0.503615</td>\n",
       "      <td>3.168815</td>\n",
       "      <td>7.121861</td>\n",
       "      <td>-1.996490</td>\n",
       "      <td>12.336751</td>\n",
       "      <td>4.156125</td>\n",
       "      <td>-87.042577</td>\n",
       "      <td>1.773479</td>\n",
       "      <td>...</td>\n",
       "      <td>27.182406</td>\n",
       "      <td>20.051316</td>\n",
       "      <td>15.919602</td>\n",
       "      <td>53.369701</td>\n",
       "      <td>-6.225449</td>\n",
       "      <td>4.779003</td>\n",
       "      <td>-4.868388</td>\n",
       "      <td>-10.691751</td>\n",
       "      <td>-7.543328</td>\n",
       "      <td>24.570621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.132692</td>\n",
       "      <td>2.539050</td>\n",
       "      <td>1.368341</td>\n",
       "      <td>3.346848</td>\n",
       "      <td>7.277713</td>\n",
       "      <td>-2.296391</td>\n",
       "      <td>12.218492</td>\n",
       "      <td>4.876927</td>\n",
       "      <td>-86.157714</td>\n",
       "      <td>2.605646</td>\n",
       "      <td>...</td>\n",
       "      <td>29.303318</td>\n",
       "      <td>20.630059</td>\n",
       "      <td>15.226790</td>\n",
       "      <td>55.438418</td>\n",
       "      <td>-6.001654</td>\n",
       "      <td>4.294154</td>\n",
       "      <td>-6.473507</td>\n",
       "      <td>-10.455375</td>\n",
       "      <td>-7.734672</td>\n",
       "      <td>23.052603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.216864</td>\n",
       "      <td>1.964295</td>\n",
       "      <td>2.222881</td>\n",
       "      <td>3.511451</td>\n",
       "      <td>7.413244</td>\n",
       "      <td>-2.614088</td>\n",
       "      <td>12.066526</td>\n",
       "      <td>5.590107</td>\n",
       "      <td>-85.191288</td>\n",
       "      <td>3.478639</td>\n",
       "      <td>...</td>\n",
       "      <td>31.366576</td>\n",
       "      <td>21.161956</td>\n",
       "      <td>14.572236</td>\n",
       "      <td>57.492671</td>\n",
       "      <td>-5.769220</td>\n",
       "      <td>3.816274</td>\n",
       "      <td>-8.047274</td>\n",
       "      <td>-10.214346</td>\n",
       "      <td>-7.895527</td>\n",
       "      <td>21.521611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.372386</td>\n",
       "      <td>1.374357</td>\n",
       "      <td>3.041033</td>\n",
       "      <td>3.657720</td>\n",
       "      <td>7.518215</td>\n",
       "      <td>-2.953332</td>\n",
       "      <td>11.879516</td>\n",
       "      <td>6.286569</td>\n",
       "      <td>-84.131576</td>\n",
       "      <td>4.375607</td>\n",
       "      <td>...</td>\n",
       "      <td>33.321630</td>\n",
       "      <td>21.626613</td>\n",
       "      <td>13.983739</td>\n",
       "      <td>59.492093</td>\n",
       "      <td>-5.537007</td>\n",
       "      <td>3.357698</td>\n",
       "      <td>-9.558303</td>\n",
       "      <td>-9.967965</td>\n",
       "      <td>-8.013550</td>\n",
       "      <td>19.994906</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   pelvis_X  pelvis_Y  pelvis_Z  L_foot_X  L_foot_Y  L_foot_Z   R_foot_X  \\\n",
       "0 -0.130881  3.623830 -0.354510  2.983322  6.958619 -1.709532  12.427321   \n",
       "1 -0.109653  3.092453  0.503615  3.168815  7.121861 -1.996490  12.336751   \n",
       "2 -0.132692  2.539050  1.368341  3.346848  7.277713 -2.296391  12.218492   \n",
       "3 -0.216864  1.964295  2.222881  3.511451  7.413244 -2.614088  12.066526   \n",
       "4 -0.372386  1.374357  3.041033  3.657720  7.518215 -2.953332  11.879516   \n",
       "\n",
       "   R_foot_Y   R_foot_Z   L_hip_X  ...   L_knee_Z   R_knee_X   R_knee_Y  \\\n",
       "0  3.441102 -87.858121  0.986488  ...  25.058309  19.450638  16.619757   \n",
       "1  4.156125 -87.042577  1.773479  ...  27.182406  20.051316  15.919602   \n",
       "2  4.876927 -86.157714  2.605646  ...  29.303318  20.630059  15.226790   \n",
       "3  5.590107 -85.191288  3.478639  ...  31.366576  21.161956  14.572236   \n",
       "4  6.286569 -84.131576  4.375607  ...  33.321630  21.626613  13.983739   \n",
       "\n",
       "    R_knee_Z  L_ankle_X  L_ankle_Y  L_ankle_Z  R_ankle_X  R_ankle_Y  R_ankle_Z  \n",
       "0  51.327518  -6.431359   5.258269  -3.270496 -10.925609  -7.332781  26.055983  \n",
       "1  53.369701  -6.225449   4.779003  -4.868388 -10.691751  -7.543328  24.570621  \n",
       "2  55.438418  -6.001654   4.294154  -6.473507 -10.455375  -7.734672  23.052603  \n",
       "3  57.492671  -5.769220   3.816274  -8.047274 -10.214346  -7.895527  21.521611  \n",
       "4  59.492093  -5.537007   3.357698  -9.558303  -9.967965  -8.013550  19.994906  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "angles = pd.DataFrame(data=angs, columns=joints_lbls)\n",
    "angles.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a3d5b0e-f742-415e-a637-5433fe119b68",
   "metadata": {},
   "source": [
    "# Run gait_steps.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1ac076c8-58c9-492f-9d90-d3b2859c62f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare environment\n",
    "# import os, sys\n",
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# #from scipy import signal\n",
    "# import scipy.io as spio\n",
    "import matlab\n",
    "import matlab.engine\n",
    "\n",
    "# from detecta import detect_peaks\n",
    "from pca_td import pca_td\n",
    "from pca_to import pca_to\n",
    "\n",
    "from scipy.signal import butter, lfilter, filtfilt\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8dcc4f82-3c1f-4381-bf0b-338770c2b042",
   "metadata": {},
   "outputs": [],
   "source": [
    "# INPUT PARAMS\n",
    "hz = data_RIC['hz_r']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "778c3460-35c6-45ca-8133-d93b373af00b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automated event detection failed, defaulting to foot-forward foot-back\n"
     ]
    }
   ],
   "source": [
    "#%% Determine functional measures and gait type (walk vs run)\n",
    "# % movement speed comes from the A/P position time history of a heel marker\n",
    "# % so we first need to identify a heel marker\n",
    "# LEFT SIDE\n",
    "# Determine functional measures and gait type (walk vs run) movement speed comes \n",
    "# from the A/P position time history of a heel marker so we first need to identify \n",
    "# a heel marker.\n",
    "\n",
    "# % Combine 3 of the foot markers into one matrix (ignore the created fourth)\n",
    "L_foot = neutral[['L_foot_1_X', 'L_foot_1_Y', 'L_foot_1_Z',\n",
    "              'L_foot_2_X', 'L_foot_2_Y', 'L_foot_2_Z',\n",
    "              'L_foot_3_X', 'L_foot_3_Y', 'L_foot_3_Z']].values.reshape((3,3))\n",
    "# sort the markers from left to right\n",
    "i_lf   = list(L_foot[:, 0].argsort())\n",
    "L_foot = L_foot[L_foot[:, 0].argsort()]\n",
    "\n",
    "# find the lower of the two medial markers\n",
    "if L_foot[1,1] < L_foot[2,1]:\n",
    "    L_marker = 'L_foot_' + str(i_lf[1]+1)\n",
    "    L_heel =  gait.filter(like=L_marker).values\n",
    "else:\n",
    "    L_marker = 'L_foot_' + str(i_lf[2]+1)\n",
    "    L_heel =  gait.filter(like=L_marker).values\n",
    "    \n",
    "# Find peaks location. Signal flipped because of X-axis convention difference.\n",
    "locs0 = detect_peaks(np.diff(L_heel[:,2]), mpd=np.round(0.5*hz), \n",
    "                    mph=0, show=False)\n",
    "pks = np.diff(L_heel[:,2])[locs0]\n",
    "\n",
    "locs = detect_peaks(-np.diff(L_heel[:,2]), mpd=np.round(0.5*hz), \n",
    "                    mph=0, show=False)\n",
    "\n",
    "# Gait velocity and cadence\n",
    "vel    = hz*np.median(pks)/1000; # gait speed\n",
    "stRate = 60/(np.median(np.diff(locs))/hz); # cadence\n",
    "#print('Gait velocity is '+str(vel)+' m/s')\n",
    "#print('Stride rate is '+str(stRate)+' strides/min')\n",
    "\n",
    "#%% RIGHT SIDE\n",
    "# % Combine 3 of the foot markers into one matrix (ignore the created fourth)\n",
    "R_foot = neutral[['R_foot_1_X', 'R_foot_1_Y', 'R_foot_1_Z',\n",
    "              'R_foot_2_X', 'R_foot_2_Y', 'R_foot_2_Z',\n",
    "              'R_foot_3_X', 'R_foot_3_Y', 'R_foot_3_Z']].values.reshape((3,3))\n",
    "# sort the markers from left to right\n",
    "i_rf   = list(R_foot[:, 0].argsort())\n",
    "R_foot = R_foot[R_foot[:, 0].argsort()]\n",
    "\n",
    "# find the lower of the two medial markers\n",
    "if R_foot[0,1] < R_foot[1,1]:\n",
    "    R_marker = 'R_foot_' + str(i_rf[0]+1)\n",
    "    R_heel =  gait.filter(like=R_marker).values\n",
    "else:\n",
    "    R_marker = 'R_foot_' + str(i_rf[1]+1)\n",
    "    R_heel =  gait.filter(like=R_marker).values\n",
    "    \n",
    "# Linear discriminant analysis\n",
    "# Import training dataset\n",
    "gaitClass = pd.read_csv(os.path.join(pathname, 'LDA_out.txt'), delimiter='\\t', \n",
    "                        header=None, names=['Category','Speed','Cadence'], usecols=[0,1,2])\n",
    "# Replace numerical by categorical\n",
    "gaitClass['Category'] = gaitClass['Category'].replace(1, 'walk')\n",
    "gaitClass['Category'] = gaitClass['Category'].replace(2, 'run')\n",
    "\n",
    "# Input to the model\n",
    "X = gaitClass[['Speed','Cadence']].values # training data\n",
    "y = gaitClass['Category'].values.tolist() # testing data\n",
    "model = LinearDiscriminantAnalysis()# define model\n",
    "model.fit(X, y) # Model fit\n",
    "\n",
    "# make a prediction\n",
    "label = model.predict(np.array([vel,stRate]).reshape((1,2)))[0]\n",
    "#print('Gait category is '+label)\n",
    "\n",
    "# Load PCA output from mat file\n",
    "# % event_data is a .mat file containing 'coeff' which is the coefficients\n",
    "# % from the pre-trained PCA and 'p' which is the list of coefficients of the\n",
    "# % linear polynomial relating PCA scores with touchdown timing relative to\n",
    "# % the foot acceleration peak.\n",
    "event_data_TD = spio.loadmat(os.path.join(pathname, 'event_data_TD.mat'))\n",
    "event_data_TO = spio.loadmat(os.path.join(pathname, 'event_data_TO.mat'))\n",
    "\n",
    "#%% Identify Touch Down and Take Off events: Gait Independent\n",
    "# % Use PCA touchdown detection based on updated Osis et al. (2014) for\n",
    "# % both walking and running.\n",
    "# % Use new PCA toeoff detection for both walking and running.\n",
    "# % evt variables are NOT rounded\n",
    "try:\n",
    "    evtLtd, evtRtd = pca_td(angles, hz, event_data_TD, label)\n",
    "    evtLto, evtRto = pca_to(angles, hz, event_data_TO, label)\n",
    "    \n",
    "except Exception as e: \n",
    "    #For a small number of people, these functions return errors, or in the\n",
    "    #case of bad data... default to use FF and FB in these cases\n",
    "    \n",
    "    evtRtd = []\n",
    "    evtRto = []\n",
    "    \n",
    "    print('Automated event detection failed, defaulting to foot-forward foot-back')\n",
    "    print(e)\n",
    "    \n",
    "## LEFT FOOT EVENTS\n",
    "# % when the feet are not tracked very well, discontinuities in the heel\n",
    "# % marker can occur causing the findpeaks to pick up additional 'peaks'\n",
    "# % for the purposes of simply identifying foot forward and foot back\n",
    "# % timing, we can over filter this signal. We do not care about the\n",
    "# % magnitude of the signal but only the timing so we can overfit as long\n",
    "# % as the filter has a zero phase shift.\n",
    "# % Note: signal is now filtered by default.  There is no advantage to not\n",
    "# % filtering, as if the signal quality is already good, then the system uses\n",
    "# % PCA event detection anyhow, and if the signal is bad, then it has to be\n",
    "# % filtered in order to get foot-forward foot-backward events.\n",
    "\n",
    "# Correct the cutoff frequency for the number of passes in the filter\n",
    "b, a = butter(2, 5/(hz/2), btype = 'low')\n",
    "# note that Python and Matlab filtfilt behaves slightly different with padding the data\n",
    "# see https://mail.python.org/pipermail/scipy-user/2014-April/035646.html\n",
    "filtered_L_heel = filtfilt(b, a, L_heel[:,2], padtype='odd')\n",
    "\n",
    "# Begin by creating a gross estimation of foot forwards and foot backs\n",
    "L_FFi = detect_peaks(-filtered_L_heel, mpd=np.round(0.35*hz),\n",
    "                     show=False)\n",
    "\n",
    "if label == 'walk':\n",
    "    # % Use peak foot flexion angle for foot back\n",
    "    # % To deal with peaks resulting from signal flipping, threshold them\n",
    "    angSig = angles['L_foot_Z'].values\n",
    "    angSig[np.abs(angSig) > 90] = np.NaN\n",
    "    L_FBi = detect_peaks(-angSig, mpd=np.round(0.7*hz),\n",
    "                     mph=20, show=False)\n",
    "else:\n",
    "    # Use rearmost position of heel marker for foot back\n",
    "    L_FBi = detect_peaks(filtered_L_heel, mpd=np.round(0.35*hz),\n",
    "                     show=False)\n",
    "    \n",
    "# %Uncomment block below to enable more aggressive quality control of data\n",
    "\n",
    "# if (np.nanpercentile(np.abs(angles['foot_Z'].values), 90) > 120) & vel < 4\n",
    "#     print('Right ankle values outside of expected ranges, please ensure your shoe markers are properly placed and redo your collection')\n",
    "#     sys.exit()\n",
    "\n",
    "# Remove any leading FB\n",
    "L_FBi = L_FBi[L_FBi>L_FFi[0]]\n",
    "\n",
    "## find largest chunk of continuous data\n",
    "\n",
    "#We want to check before and after that there is sufficient data for analysis\n",
    "\n",
    "if (L_FFi.shape[0] < 2) or (L_FBi.shape[0] < 2):\n",
    "    print('Automated event detection unable to pull adequate number of strides for analysis. Please redo your data collection.')\n",
    "    sys.exit()\n",
    "    \n",
    "# Call Matlab function LARGEST_BLOCK.m from Python\n",
    "eng = matlab.engine.start_matlab() # start Matlab engine\n",
    "eng.cd(r'../functions', nargout=0) # set path for functions dir\n",
    "\n",
    "\n",
    "L_FFi, L_FBi, L_block_start, block_end = eng.largest_block(matlab.double(list(L_FFi)), \n",
    "                                                             matlab.double(list(L_FBi)), nargout=4)\n",
    "\n",
    "L_FFi = np.array(L_FFi).flatten().astype(int)\n",
    "L_FBi = np.array(L_FBi).flatten().astype(int)\n",
    "\n",
    "if (L_FFi.shape[0] < 2) or (L_FBi.shape[0] < 2):\n",
    "    print('Automated event detection unable to pull adequate number of strides for analysis. Please redo your data collection.')\n",
    "    sys.exit()\n",
    "    \n",
    "# TOUCHDOWN\n",
    "# evtLtd from above\n",
    "\n",
    "# SELECT SEQUENTIAL STEPS\n",
    "# create an ordered set of sequential steps using FFi as guide\n",
    "closest = np.abs(np.repeat(L_FFi[:,np.newaxis], evtLtd.shape[0], axis=1)-np.repeat(evtLtd[:,np.newaxis].T, L_FFi.shape[0], axis=0))\n",
    "\n",
    "mindist, minx = np.nanmin(closest, axis=0), np.nanargmin(closest, axis=0)\n",
    "\n",
    "for i in np.unique(minx).astype(int):\n",
    "    if np.sum(np.isin(i,minx)) > 1:\n",
    "        mindist = mindist[minx!=i]\n",
    "        evtLtd  = evtLtd[minx!=i]\n",
    "        minx    = minx[minx!=i]\n",
    "        \n",
    "# Parameter based on the typical frame adjustments observed in 300\n",
    "# datasets\n",
    "if label=='run':\n",
    "    maxadj = 0.05*hz\n",
    "else:\n",
    "    maxadj = 0.10*hz\n",
    "    \n",
    "# Preallocate\n",
    "L_TD = np.empty(L_FFi.shape[0]) * np.NaN\n",
    "evFltd = np.zeros(L_FFi.shape[0])\n",
    "\n",
    "# Here we replace FF indices with indices from evt where criteria are\n",
    "# met... the default is to use FF\n",
    "for i in range(L_FFi.shape[0]):\n",
    "    try:\n",
    "        if i > np.max(minx):\n",
    "            break\n",
    "        elif np.isin(i,minx) and mindist[minx==i] < maxadj:\n",
    "            #Replace with evtLtd since its more accurate\n",
    "            L_TD[i] = evtLtd[minx==i]\n",
    "            evFltd[i] = 1\n",
    "        else:\n",
    "            #Use FFi since it is more robust\n",
    "            L_TD[i] = L_FFi[i]\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        L_TD[i] = L_FFi[i]\n",
    "        \n",
    "# %% TAKEOFF\n",
    "\n",
    "# % evtLto from above\n",
    "\n",
    "# % SELECT SEQUENTIAL STEPS\n",
    "\n",
    "# % Now create an ordered set of sequential steps using FBi as guide\n",
    "closest = np.abs(np.repeat(L_FBi[:,np.newaxis], evtLto.shape[0], axis=1)-np.repeat(evtLto[:,np.newaxis].T, L_FBi.shape[0], axis=0))\n",
    "\n",
    "mindist, minx = np.nanmin(closest, axis=0), np.nanargmin(closest, axis=0)\n",
    "for i in np.unique(minx).astype(int):\n",
    "    if np.sum(np.isin(i,minx)) > 1:\n",
    "        mindist = mindist[minx!=i]\n",
    "        evtLtd  = evtLtd[minx!=i]\n",
    "        minx    = minx[minx!=i]\n",
    "        \n",
    "# Parameter based on the frame adjustment observed from 300 datasets\n",
    "maxadj = 0.15*hz\n",
    "\n",
    "# Preallocate\n",
    "L_TO = np.empty(L_FBi.shape[0]) * np.NaN\n",
    "evFlto = np.zeros(L_FBi.shape[0])\n",
    "\n",
    "# Here we replace FB indices with TO from PCA default is to use FB\n",
    "for i in range(L_FBi.shape[0]):\n",
    "    try:\n",
    "        if i > np.max(minx):\n",
    "            break\n",
    "        elif np.isin(i,minx) and mindist[minx==i] < maxadj:\n",
    "            #Replace with evtLto since its more accurate\n",
    "            L_TO[i] = evtLto[minx==i]\n",
    "            evFlto[i] = 1\n",
    "        else:\n",
    "            #Use FFi since it is more robust\n",
    "            L_TO[i] = L_FBi[i]\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        L_TO[i] = L_FBi[i]\n",
    "\n",
    "# Finally we round to get final indices\n",
    "L_TD = L_TD.round()\n",
    "L_TO = L_TO.round()\n",
    "\n",
    "\n",
    "# %% RIGHT FOOT EVENTS\n",
    "# % the same steps we just took for the left side\n",
    "\n",
    "# % Begin by creating a gross estimation of foot forwards and foot backs\n",
    "# Correct the cutoff frequency for the number of passes in the filter\n",
    "b, a = butter(2, 5/(hz/2), btype = 'low')\n",
    "# note that Python and Matlab filtfilt behaves slightly different with padding the data\n",
    "# see https://mail.python.org/pipermail/scipy-user/2014-April/035646.html\n",
    "filtered_R_heel = filtfilt(b, a, R_heel[:,2], padtype='odd')\n",
    "\n",
    "# Begin by creating a gross estimation of foot forwards and foot backs\n",
    "R_FFi = detect_peaks(-filtered_R_heel, mpd=np.round(0.35*hz),\n",
    "                     show=False)\n",
    "\n",
    "if label == 'walk':\n",
    "    # % Use peak foot flexion angle for foot back\n",
    "    # % To deal with peaks resulting from signal flipping, threshold them\n",
    "    angSig = angles['R_foot_Z'].values\n",
    "    angSig[np.abs(angSig) > 90] = np.NaN\n",
    "    R_FBi = detect_peaks(-angSig, mpd=np.round(0.7*hz),\n",
    "                     mph=20, show=False)\n",
    "else:\n",
    "    # Use rearmost position of heel marker for foot back\n",
    "    R_FBi = detect_peaks(filtered_R_heel, mpd=np.round(0.35*hz),\n",
    "                     show=False)\n",
    "    \n",
    "# %Uncomment block below to enable more aggressive quality control of data\n",
    "\n",
    "# if (np.nanpercentile(np.abs(angles['R_foot_Z'].values), 90) > 120) & vel < 4\n",
    "#     print('Right ankle values outside of expected ranges, please ensure your shoe markers are properly placed and redo your collection')\n",
    "#     sys.exit()\n",
    "\n",
    "# Remove any leading FB\n",
    "R_FFi = R_FFi[R_FFi>L_FFi[0]]\n",
    "R_FBi = R_FBi[R_FBi>R_FFi[0]]\n",
    "\n",
    "## find largest chunk of continuous data\n",
    "\n",
    "#We want to check before and after that there is sufficient data for analysis\n",
    "\n",
    "if (R_FFi.shape[0] < 2) or (R_FBi.shape[0] < 2):\n",
    "    print('Automated event detection unable to pull adequate number of strides for analysis. Please redo your data collection.')\n",
    "    sys.exit()\n",
    "    \n",
    "    \n",
    "# LARGEST_BLOCK\n",
    "R_FFi, R_FBi, R_block_start, R_block_end = eng.largest_block(matlab.double(list(R_FFi)), \n",
    "                                                             matlab.double(list(R_FBi)), nargout=4)\n",
    "\n",
    "R_FFi = np.array(R_FFi).flatten().astype(int)\n",
    "R_FBi = np.array(R_FBi).flatten().astype(int)\n",
    "\n",
    "if (R_FFi.shape[0] < 2) or (R_FBi.shape[0] < 2):\n",
    "    print('Automated event detection unable to pull adequate number of strides for analysis. Please redo your data collection.')\n",
    "    sys.exit()\n",
    "    \n",
    "# %In rare instances a the index will be in incorrect order run below again\n",
    "# %in case\n",
    "\n",
    "# % Remove any leading FF and FB\n",
    "R_FFi = R_FFi[R_FFi>L_FFi[0]]\n",
    "R_FBi = R_FBi[R_FBi>R_FFi[0]]\n",
    "\n",
    "# TOUCHDOWN\n",
    "# evtRtd from above\n",
    "\n",
    "# SELECT SEQUENTIAL STEPS\n",
    "# create an ordered set of sequential steps using FFi as guide\n",
    "closest = np.abs(np.repeat(R_FFi[:,np.newaxis], evtRtd.shape[0], axis=1)-np.repeat(evtRtd[:,np.newaxis].T, R_FFi.shape[0], axis=0))\n",
    "\n",
    "mindist, minx = np.nanmin(closest, axis=0), np.nanargmin(closest, axis=0)\n",
    "\n",
    "for i in np.unique(minx).astype(int):\n",
    "    if np.sum(np.isin(i,minx)) > 1:\n",
    "        mindist = mindist[minx!=i]\n",
    "        evtLtd  = evtLtd[minx!=i]\n",
    "        minx    = minx[minx!=i]\n",
    "        \n",
    "# Parameter based on the typical frame adjustments observed in 300\n",
    "# datasets\n",
    "if label=='run':\n",
    "    maxadj = 0.05*hz\n",
    "else:\n",
    "    maxadj = 0.10*hz\n",
    "    \n",
    "# Preallocate\n",
    "R_TD = np.empty(R_FFi.shape[0]) * np.NaN\n",
    "evFrtd = np.zeros(R_FFi.shape[0])\n",
    "\n",
    "# Here we replace FF indices with indices from evt where criteria are\n",
    "# met... the default is to use FF\n",
    "for i in range(R_FFi.shape[0]):\n",
    "    try:\n",
    "        if i > np.max(minx):\n",
    "            break\n",
    "        elif np.isin(i,minx) and mindist[minx==i] < maxadj:\n",
    "            #Replace with evtRtd since its more accurate\n",
    "            R_TD[i] = evtRtd[minx==i]\n",
    "            evFrtd[i] = 1\n",
    "        else:\n",
    "            #Use FFi since it is more robust\n",
    "            R_TD[i] = R_FFi[i]\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        R_TD[i] = R_FFi[i]\n",
    "        \n",
    "        \n",
    "# %% TAKEOFF\n",
    "\n",
    "# % evtRto from above\n",
    "\n",
    "# % SELECT SEQUENTIAL STEPS\n",
    "\n",
    "# % Now create an ordered set of sequential steps using FBi as guide\n",
    "closest = np.abs(np.repeat(R_FBi[:,np.newaxis], evtRto.shape[0], axis=1)-np.repeat(evtRto[:,np.newaxis].T, R_FBi.shape[0], axis=0))\n",
    "\n",
    "mindist, minx = np.nanmin(closest, axis=0), np.nanargmin(closest, axis=0)\n",
    "for i in np.unique(minx).astype(int):\n",
    "    if np.sum(np.isin(i,minx)) > 1:\n",
    "        mindist = mindist[minx!=i]\n",
    "        evtLtd  = evtLtd[minx!=i]\n",
    "        minx    = minx[minx!=i]\n",
    "        \n",
    "# Parameter based on the frame adjustment observed from 300 datasets\n",
    "maxadj = 0.15*hz\n",
    "\n",
    "# Preallocate\n",
    "R_TO = np.empty(R_FBi.shape[0]) * np.NaN\n",
    "evFrto = np.zeros(R_FBi.shape[0])\n",
    "\n",
    "# Here we replace FB indices with TO from PCA default is to use FB\n",
    "for i in range(R_FBi.shape[0]):\n",
    "    try:\n",
    "        if i > np.max(minx):\n",
    "            break\n",
    "        elif np.isin(i,minx) and mindist[minx==i] < maxadj:\n",
    "            #Replace with evtLto since its more accurate\n",
    "            R_TO[i] = evtRto[minx==i]\n",
    "            evFrto[i] = 1\n",
    "        else:\n",
    "            #Use FFi since it is more robust\n",
    "            R_TO[i] = R_FBi[i]\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        R_TO[i] = R_FBi[i]\n",
    "\n",
    "# Finally we round to get final indices\n",
    "R_TD = R_TD.round()\n",
    "R_TO = R_TO.round()\n",
    "\n",
    "# %% if largest chunk of continuous data not at beginning, chop both right and left so they match\n",
    "\n",
    "\n",
    "# %index must begin with left touchdown and end with right toe\n",
    "# %off\n",
    "\n",
    "\n",
    "if R_block_start < L_block_start:\n",
    "    #remove all right indices that occur before the first left touchdown\n",
    "    \n",
    "    R_TO = R_TO[(R_TD < L_block_start)!=1]\n",
    "    R_TD = R_TD[(R_TD < L_block_start)!=1]\n",
    "    \n",
    "flag = 0\n",
    "\n",
    "if L_block_start < R_block_start:\n",
    "    #remove left touchdowns more than one touchdown before the first right touchdown\n",
    "    cut_inds = (L_TD<R_block_start)==1\n",
    "    cut_inds.astype(int)\n",
    "    #this loop ensures the first index will be a left touchdown\n",
    "    for i in range(cut_inds.shape[0]):\n",
    "        if (cut_inds[i]==1) and (cut_inds[i+1]==0) and flag==0:\n",
    "            cut_inds[i] = 0\n",
    "            flag = 1\n",
    "            \n",
    "    L_TD = np.delete(L_TD, cut_inds)\n",
    "    L_TO = np.delete(L_TO, cut_inds)\n",
    "    \n",
    "    \n",
    "# create an events matrix\n",
    "# Remove trailing nans that may have crept in\n",
    "evFltd = evFltd[~np.isnan(L_TD)]\n",
    "evFlto = evFlto[~np.isnan(L_TO)]\n",
    "evFrtd = evFrtd[~np.isnan(R_TD)]\n",
    "evFrto = evFrto[~np.isnan(R_TO)]\n",
    "\n",
    "L_TD = L_TD[~np.isnan(L_TD)]\n",
    "L_TO = L_TO[~np.isnan(L_TO)]\n",
    "R_TD = R_TD[~np.isnan(R_TD)]\n",
    "R_TO = R_TO[~np.isnan(R_TO)]\n",
    "\n",
    "# Find the closest ordered pairs of L_TO and R_TD to synchronize steps\n",
    "closest = np.abs(np.repeat(R_TD[:,np.newaxis], L_TO.shape[0], axis=1)-np.repeat(L_TO[:,np.newaxis].T, R_TD.shape[0], axis=0))\n",
    "\n",
    "minx = np.nanargmin(closest,axis=0)\n",
    "\n",
    "#Truncate right stances to match up with left\n",
    "evFrtd = evFrtd[np.unique(minx)]\n",
    "R_TD = R_TD[np.unique(minx)]\n",
    "\n",
    "\n",
    "testlength = np.min([L_TO.shape[0], R_TD.shape[0]])\n",
    "if np.median(L_TO[:testlength]-R_TD[:testlength]) < 0:#Then there is a flight phase\n",
    "    #Find the closest ordered pairs of R_TD and R_TO to synchronize steps\n",
    "    closest = np.abs(np.repeat(R_TO[:,np.newaxis], R_TD.shape[0], axis=1)-np.repeat(R_TD[:,np.newaxis].T, R_TO.shape[0], axis=0))\n",
    "    minx = np.nanargmin(closest,axis=0)\n",
    "    \n",
    "else: # There is no flight phase i.e. grounded running or walking\n",
    "    #Find the closest ordered pairs of R_TO and L_TD to synchronize steps\n",
    "    tmp = L_TD[1:]\n",
    "    closest = np.abs(np.repeat(R_TO[:,np.newaxis], tmp.shape[0], \n",
    "                               axis=1)-np.repeat(tmp[:,np.newaxis].T, R_TO.shape[0], axis=0))\n",
    "    minx = np.nanargmin(closest,axis=0)\n",
    "    \n",
    "evFrto = evFrto[np.unique(minx)]\n",
    "R_TO = R_TO[np.unique(minx)]\n",
    "\n",
    "events = [L_TD.shape[0], L_TO.shape[0], R_TD.shape[0], R_TO.shape[0]]\n",
    "\n",
    "# Chop everything to the same length\n",
    "L_TD = L_TD[:min(events)]\n",
    "L_TO = L_TO[:min(events)]\n",
    "R_TD = R_TD[:min(events)]\n",
    "R_TO = R_TO[:min(events)]\n",
    "\n",
    "evFltd = evFltd[:min(events)]\n",
    "evFlto = evFlto[:min(events)]\n",
    "evFrtd = evFrtd[:min(events)]\n",
    "evFrto = evFrto[:min(events)]\n",
    "\n",
    "# Very rarely, these will wind up empty and assignment doesn't work\n",
    "events = np.empty(shape=(L_TD.shape[0],4)) * np.NaN\n",
    "events[:,0]=L_TD\n",
    "events[:,1]=L_TO\n",
    "events[:,2]=R_TD\n",
    "events[:,3]=R_TO\n",
    "# Very rarely, these will wind up empty and assignment doesn't work\n",
    "eventsflag = np.empty(shape=(evFltd.shape[0],4)) * np.NaN\n",
    "eventsflag[:,0]=evFltd\n",
    "eventsflag[:,1]=evFlto\n",
    "eventsflag[:,2]=evFrtd\n",
    "eventsflag[:,3]=evFrto\n",
    "\n",
    "# Remove first row since these will very often be reliant on FF and FB measures\n",
    "if events.shape[0] > 1:\n",
    "    events = np.delete(events,0,axis=0)\n",
    "    eventsflag = np.delete(eventsflag,0,axis=0)\n",
    "    \n",
    "# %% Occasionally, one stance will drop out, and data becomes\n",
    "# % discontinuous...this fix alleviates this by trimming data to largest\n",
    "# % continuous block\n",
    "try:\n",
    "    cont = np.array([events[1:,0]>events[:-1,1],events[1:,2]>events[:-1,3]])\n",
    "    cont = np.hstack((np.zeros((2,1)),cont,np.zeros((2,1)))).T\n",
    "    F = np.where(np.any(cont==0, axis=1))\n",
    "    F = np.asarray(F).flatten()\n",
    "    D = np.diff(F)-2\n",
    "    M, L = np.max(D), np.argmax(D)\n",
    "    events = events[F[L]:F[L]+M+1,:]\n",
    "    eventsflag = eventsflag[F[L]:F[L]+M+1,:]\n",
    "except Exception as e:\n",
    "    print('Could not obtain a continuous block of events')\n",
    "    events = []\n",
    "    eventsflag = []\n",
    "    print(e)\n",
    "    \n",
    "# Worst-case... return to foot forward, foot back detection\n",
    "if events.shape[0] < 5:\n",
    "    print('Automated event detection failed, defaulting to foot-forward foot-back')\n",
    "    nevents = [L_FFi.shape[0], L_FBi.shape[0], R_FFi.shape[0], R_FBi.shape[0]]\n",
    "    \n",
    "    # Chop everything to the same length\n",
    "    L_FFi = L_FFi[:min(nevents)]\n",
    "    L_FBi = L_FBi[:min(nevents)]\n",
    "    R_FFi = R_FFi[:min(nevents)]\n",
    "    R_FBi = R_FBi[:min(nevents)]\n",
    "    \n",
    "    events = np.empty(shape=(min(nevents),4)) * np.NaN\n",
    "    events[:,0] = L_FFi\n",
    "    events[:,1] = L_FBi\n",
    "    events[:,2] = R_FFi\n",
    "    events[:,3] = R_FBi\n",
    "    \n",
    "# Pull event columns from events so everything is consistent\n",
    "L_TD = events[:,0]\n",
    "L_TO = events[:,1]\n",
    "R_TD = events[:,2]\n",
    "R_TO = events[:,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2d385daf-b5a8-4e95-98c5-d065551a1589",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 118.,  248.,  378.,  510.,  640.,  770.,  901., 1030., 1161.,\n",
       "       1291., 1421., 1552., 1682., 1811., 1942., 2074., 2204., 2335.,\n",
       "       2465., 2596., 2728., 2858., 2989., 3119., 3248., 3378., 3509.,\n",
       "       3639., 3769., 3900., 4030., 4161., 4290., 4419., 4548., 4679.,\n",
       "       4808.])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L_TD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dfae31c0-0cb0-4f36-b871-618c10b4a582",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 184.,  313.,  435.,  576.,  706.,  836.,  966., 1096., 1228.,\n",
       "       1357., 1488., 1618., 1744., 1876., 2008., 2141., 2262., 2400.,\n",
       "       2522., 2663., 2793., 2924., 3055., 3185., 3313., 3444., 3573.,\n",
       "       3704., 3835., 3965., 4095., 4225., 4355., 4484., 4615., 4745.,\n",
       "       4872.])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L_TO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9ff14f38-c885-4cf7-a6c2-2dcc4efb08a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 188.,  313.,  437.,  574.,  704.,  843.,  972., 1095., 1222.,\n",
       "       1351., 1485., 1616., 1747., 1878., 2014., 2137., 2272., 2399.,\n",
       "       2524., 2659., 2786., 2917., 3045., 3182., 3314., 3443., 3569.,\n",
       "       3703., 3832., 3964., 4095., 4216., 4353., 4486., 4616., 4743.,\n",
       "       4874.])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R_TD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7013eb8-83ef-42af-8d4e-32526421ec2f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2cad6c8-945b-406f-9bf4-eb2cd47e5909",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
