{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b12e57ac",
   "metadata": {},
   "source": [
    "# Gait steps\n",
    "\n",
    "Reginaldo K Fukuchi \n",
    "\n",
    "This NB implements the \"gait_steps.m\" Sean Osis method to detect gait events.\n",
    "\n",
    "To make RBDS reference system convention consistent to RIC\n",
    "\n",
    "RBDS Lab Coordinate system\n",
    "*       X - points to the driection of walking\n",
    "*       Y - points vertically upwards\n",
    "*       Z - points to the subject's right\n",
    "\n",
    "RIC the following Lab Coordinate system\n",
    "*       X - points to the subject's right\n",
    "*       Y - points vertically upwards\n",
    "*       Z - points opposite of the walking direction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f4e9cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare environment\n",
    "import os, glob, sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import signal\n",
    "import scipy.io as spio\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "from detecta import detect_peaks\n",
    "\n",
    "import sys\n",
    "sys.path.insert(1, r'../functions')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23d21fe2-af84-4172-9bb3-7bf8ff196d2c",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Supporting functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a772a5a-daba-4bb4-8bb0-cdd7c6ff17f8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def f7(seq):\n",
    "    seen = set()\n",
    "    seen_add = seen.add\n",
    "    return [x for x in seq if not (x in seen or seen_add(x))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5529672e-06a6-4630-abb7-82d590d9d61f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = r'C:\\Users\\Reginaldo\\Documents\\data\\CNPq\\RBDS_v2\\Figshare'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03e13ca3-8ea3-4b5c-b298-27cd11d5eb98",
   "metadata": {},
   "source": [
    "## Troubleshoot gait_steps.py\n",
    "Sometimes the code is throwing the following warning/error: **\"setting an array element with a sequence.\"**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a40dae9",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5907274e-f239-4c86-a4d3-cfa502ef1b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import parse_gait_kinematics as parse_gait"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05a89ddf-799f-48d9-acb9-c16363cb96cf",
   "metadata": {},
   "source": [
    "### RIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29a2f0ae-1333-4da0-b1b1-9c2368d25744",
   "metadata": {},
   "outputs": [],
   "source": [
    "# figshare_dir = r'C:\\Users\\Reginaldo\\OneDrive - University of Calgary\\data\\Figshare_SciData\\new_unzip'\n",
    "# fn_json=os.path.join(figshare_dir, '201225', '20140515T133244.json')\n",
    "\n",
    "# neutral_RIC, joints_RIC, gait_RIC, hz_RIC = parse_gait_kinematics.parse_RIC(fn_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb49ef40-2073-4a2f-b803-3b1069dae336",
   "metadata": {},
   "source": [
    "### RBDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aa5dfbf-0e4f-48ef-954b-d2d4770be1e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fn_static = os.path.join(data_dir,'RBDS001static.c3d')\n",
    "fn_gait = os.path.join(data_dir,'RBDS001runT35.c3d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b4ec5bd-b92b-4c29-8459-1ba83cefc607",
   "metadata": {},
   "outputs": [],
   "source": [
    "neutral, joints, gait, hz = parse_gait.parse_RBDS(fn_static, fn_gait)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdb4d797-cbf5-4a27-be9f-1b84c2dcca94",
   "metadata": {},
   "source": [
    "### Run gait_kinematics.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa1732fc-7a70-4a6c-8af4-ed4aacf36673",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gait_kinematics import gait_kinematics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ada83b-2668-4cb2-93b2-d5ca662e1d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Invoking function to calculate angles\n",
    "angle_L_ankle, angle_R_ankle, angle_L_knee, angle_R_knee, angle_L_hip, angle_R_hip, angle_L_foot, angle_R_foot, angle_Pelvis = gait_kinematics(joints, neutral, gait, hz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f823acc3-59d9-4e31-ae82-15914325c2aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "angle_L_ankle, angle_R_ankle = angle_L_ankle*(180/np.pi), angle_R_ankle*(180/np.pi)\n",
    "angle_L_knee, angle_R_knee   = angle_L_knee*(180/np.pi), angle_R_knee*(180/np.pi)\n",
    "angle_L_hip, angle_R_hip     = angle_L_hip*(180/np.pi), angle_R_hip*(180/np.pi)\n",
    "angle_L_foot, angle_R_foot   = angle_L_foot*(180/np.pi), angle_R_foot*(180/np.pi)\n",
    "angle_Pelvis  = angle_Pelvis * (180/np.pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46c552f8-dc3a-4ecb-8d20-f566e31e822e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataframe column corresponding to the dataset\n",
    "joints_lbls = ['pelvis','L_foot','R_foot','L_hip','R_hip','L_knee','R_knee',\n",
    "               'L_ankle','R_ankle']\n",
    "xyz = list('XYZ')*len(joints_lbls)\n",
    "joints_lbls = [ele for ele in joints_lbls for i in range(3)]\n",
    "joints_lbls = [joints_lbls[i]+'_'+xyz[i] for i in range(len(xyz))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab57238e-3031-46c6-b4ef-642542320dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "angs = np.hstack([angle_Pelvis, angle_L_foot, angle_R_foot, \n",
    "                  angle_L_hip, angle_R_hip, angle_L_knee, angle_R_knee, \n",
    "                  angle_L_ankle, angle_R_ankle])\n",
    "angles = pd.DataFrame(data=angs, columns=joints_lbls)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a3d5b0e-f742-415e-a637-5433fe119b68",
   "metadata": {},
   "source": [
    "# Run gait_steps.py\n",
    "Sometimes the code is throwing the following warning/error: **\"setting an array element with a sequence.\"**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cc74021-acb6-4f0b-9c16-ffe05e668cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gait_steps import gait_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8b0b692-6424-49d2-9e2c-3d7424a61256",
   "metadata": {},
   "outputs": [],
   "source": [
    "L_TD, L_TO, R_TD, R_TO, eventsflag, label = gait_steps(neutral, gait, angles, hz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "799b0b7b-6c3c-4f3e-b3ae-64122113cddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "joints = ['hip','knee','ankle']\n",
    "axes = ['X','Y','Z']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f84cdf63-1094-4e1d-8c67-0c3e5a9e0058",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Plot angles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cd88daa-d222-45b8-b918-d8a862a9e23f",
   "metadata": {},
   "outputs": [],
   "source": [
    "rtd = R_TD.astype(int).tolist()\n",
    "rto = R_TO.astype(int).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c210e76-dad2-4c6b-9618-f8accfce021e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(3,3, figsize=(10,6))\n",
    "fig.suptitle('Hip, knee and ankle angles')\n",
    "for j, joint in enumerate(joints):\n",
    "    ang = angles.filter(like='R_'+joint).values\n",
    "    for xyz, eixo in enumerate(axes):\n",
    "        for i in range(len(rtd)-1):\n",
    "            axs[j,xyz].plot(ang[rtd[i]:rtd[i+1], xyz])\n",
    "            axs[j,xyz].set_ylabel(joint+'_'+eixo)\n",
    "            axs[j,xyz].grid('on')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb517685-8152-4cbe-af7d-46c4e97732bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(3, figsize=(10,6))\n",
    "fig.suptitle('Comparison of LEFT ankle angles between methods')\n",
    "axs[0].plot(angle_L_ankle[:,0], 'b', label='Python')\n",
    "axs[0].plot(tn[0::3],anga_matlab[0::3,0], 'b*', label='Matlab')\n",
    "axs[0].grid('on')\n",
    "axs[1].plot(angle_L_ankle[:,1], 'r', label='Python')\n",
    "axs[1].plot(tn[0::3],anga_matlab[0::3,1], 'r*', label='Matlab')\n",
    "axs[1].grid('on')\n",
    "axs[2].plot(angle_L_ankle[:,2], 'g', label='Python')\n",
    "axs[2].plot(tn[0::3],anga_matlab[0::3,2], 'g*', label='Matlab')\n",
    "axs[2].grid('on')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42e143be-c5af-4922-ae66-298d5d98cfdd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5886ea1b-1416-4a4b-b9de-67fd7c6e0f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tnorma import tnorma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82e81670-d63f-4db6-a472-6125a626286b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ang_hip = np.empty(shape=(101,iTD.shape[0]-1,3))\n",
    "ang_knee= np.empty(shape=(101,iTD.shape[0]-1,3))\n",
    "for i in range(iTD.shape[0]-1):\n",
    "    ang_hip[:,i,:], tn, indie = tnorma(angh_r[iTD[i]:iTD[i+1],:], k=1, \n",
    "                                       smooth=0, mask=None, show=False)\n",
    "    ang_knee[:,i,:], tn, indie= tnorma(angk_r[iTD[i]:iTD[i+1],:], k=1, \n",
    "                                       smooth=0, mask=None, show=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e022b0-b62f-4a43-967c-3b4eba5fbd33",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(3, figsize=(10,6))\n",
    "fig.suptitle('Comparison of LEFT ankle angles between methods')\n",
    "axs[0].plot(angle_L_ankle[:,0], 'b', label='Python')\n",
    "axs[0].plot(tn[0::3],anga_matlab[0::3,0], 'b*', label='Matlab')\n",
    "axs[0].grid('on')\n",
    "axs[1].plot(angle_L_ankle[:,1], 'r', label='Python')\n",
    "axs[1].plot(tn[0::3],anga_matlab[0::3,1], 'r*', label='Matlab')\n",
    "axs[1].grid('on')\n",
    "axs[2].plot(angle_L_ankle[:,2], 'g', label='Python')\n",
    "axs[2].plot(tn[0::3],anga_matlab[0::3,2], 'g*', label='Matlab')\n",
    "axs[2].grid('on')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e69e2d32-6794-4ef1-9367-002b4494a6f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7624cb6c-c6de-4e40-a03a-c7bf4644b442",
   "metadata": {},
   "source": [
    "# Visualize Markers\n",
    "## RIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a6d4ff3-1987-4a17-83ef-2dd42aff1df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c77fcd7c-a90b-427f-9625-842cb532ba8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average marker position\n",
    "mkr_S = neutral_RIC.values.flatten()\n",
    "# Marker labels list\n",
    "mkr_S_lbl = [neutral_RIC.columns.tolist()[i][:-2] for i in range(mkr_S.shape[0])]\n",
    "mkr_S_lbl_ = f7(mkr_S_lbl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "584a8976-2489-436d-98ed-6b4db192143e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "fig = plt.figure(figsize=(8, 10))\n",
    "ax = fig.add_subplot(111, projection='3d',  facecolor='white')\n",
    "ax.view_init(90, -90, vertical_axis='z')\n",
    "\n",
    "\n",
    "ax.scatter(mkr_S[0:-3:3], mkr_S[1:-2:3], mkr_S[2:-1:3], c='r', s=30, depthshade=False)\n",
    "for m, mkr_lbl in enumerate(mkr_S_lbl_):\n",
    "    ax.text(mkr_S[3*m], mkr_S[3*m+1], mkr_S[3*m+2], mkr_lbl)\n",
    "\n",
    "ax.set_xlim3d([np.nanmin(mkr_S[0::3])-.4, np.nanmax(mkr_S[0::3])+.4])\n",
    "ax.set_ylim3d([np.nanmin(mkr_S[1::3])-.4, np.nanmax(mkr_S[1::3])+.4])\n",
    "ax.set_zlim3d([np.nanmin(mkr_S[2::3]), np.nanmax(mkr_S[2::3])])\n",
    "ax.set_xlabel('\\n' + 'X [m]', linespacing=2)\n",
    "ax.set_ylabel('\\n' + 'Y [m]', linespacing=2)\n",
    "ax.set_zlabel('\\n' + 'Z [m]', linespacing=2)\n",
    "#ax.invert_yaxis()\n",
    "# square plot\n",
    "ax.set_aspect('equal', adjustable='box')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6430c7db-bec5-4b55-80a6-c178c35e2f6d",
   "metadata": {},
   "source": [
    "## RBDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7884d69a-178f-4c69-a1f2-5d7a60cf991f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average marker position\n",
    "mkr_S = neutral.values.flatten()\n",
    "# Marker labels list\n",
    "mkr_S_lbl = [neutral.columns.tolist()[i][:-2] for i in range(mkr_S.shape[0])]\n",
    "mkr_S_lbl_ = f7(mkr_S_lbl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94b5da63-6860-4e85-9179-73430be4fe08",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "fig = plt.figure(figsize=(8, 10))\n",
    "ax = fig.add_subplot(111, projection='3d',  facecolor='white')\n",
    "ax.view_init(90, -90, vertical_axis='z')\n",
    "\n",
    "\n",
    "ax.scatter(mkr_S[0:-3:3], mkr_S[1:-2:3], mkr_S[2:-1:3], c='r', s=30, depthshade=False)\n",
    "for m, mkr_lbl in enumerate(mkr_S_lbl_):\n",
    "    ax.text(mkr_S[3*m], mkr_S[3*m+1], mkr_S[3*m+2], mkr_lbl)\n",
    "\n",
    "ax.set_xlim3d([np.nanmin(mkr_S[0::3])-.4, np.nanmax(mkr_S[0::3])+.4])\n",
    "ax.set_ylim3d([np.nanmin(mkr_S[1::3])-.4, np.nanmax(mkr_S[1::3])+.4])\n",
    "ax.set_zlim3d([np.nanmin(mkr_S[2::3]), np.nanmax(mkr_S[2::3])])\n",
    "ax.set_xlabel('\\n' + 'X [m]', linespacing=2)\n",
    "ax.set_ylabel('\\n' + 'Y [m]', linespacing=2)\n",
    "ax.set_zlabel('\\n' + 'Z [m]', linespacing=2)\n",
    "#ax.invert_yaxis()\n",
    "# square plot\n",
    "ax.set_aspect('equal', adjustable='box')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf5be367-1013-4e27-ad6a-2c4f3ccee4f4",
   "metadata": {},
   "source": [
    "# Script used to write gait_steps.py\n",
    "Leave in the bottom of the NB in case I need to troubleshoot later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "934ab453-e5a6-488f-ab08-a84c3819ae0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare environment\n",
    "import os, sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "#from scipy import signal\n",
    "import scipy.io as spio\n",
    "import matlab\n",
    "import matlab.engine\n",
    "\n",
    "import sys\n",
    "sys.path.insert(1, r'../functions')\n",
    "\n",
    "from detecta import detect_peaks\n",
    "from pca_td import pca_td\n",
    "from pca_to import pca_to\n",
    "\n",
    "from scipy.signal import butter, lfilter, filtfilt\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "db0429b9-6862-4b2b-a179-3874d8216144",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = r'C:\\Users\\Reginaldo\\Documents\\data\\CNPq\\RBDS_v2\\Figshare'\n",
    "fn_static = os.path.join(data_dir, 'RBDS001static.c3d')\n",
    "fn_gait = os.path.join(data_dir, 'RBDS001runT35.c3d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "01fd4cdc-6ccc-43b0-be3a-0f97f9479f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import parse_gait_kinematics as parse_gait\n",
    "from gait_kinematics import gait_kinematics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b6fc4679-af26-4723-8744-1517cc765ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataframe column corresponding to the dataset\n",
    "joints_lbls = ['pelvis','L_foot','R_foot','L_hip','R_hip','L_knee','R_knee',\n",
    "               'L_ankle','R_ankle']\n",
    "xyz = list('XYZ')*len(joints_lbls)\n",
    "joints_lbls = [ele for ele in joints_lbls for i in range(3)]\n",
    "joints_lbls = [joints_lbls[i]+'_'+xyz[i] for i in range(len(xyz))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "381bf539-c4ec-43ee-8909-a7cc631375d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "neutral, joints, gait, hz = parse_gait.parse_RBDS(fn_static, fn_gait)\n",
    "\n",
    "# Invoking function to calculate angles\n",
    "angle_L_ankle, angle_R_ankle, angle_L_knee, angle_R_knee, angle_L_hip, angle_R_hip, angle_L_foot, angle_R_foot, angle_Pelvis = gait_kinematics(joints, neutral, gait, hz)\n",
    "# Convert to degrees\n",
    "angle_L_ankle, angle_R_ankle = angle_L_ankle*(180/np.pi), angle_R_ankle*(180/np.pi)\n",
    "angle_L_knee, angle_R_knee   = angle_L_knee*(180/np.pi), angle_R_knee*(180/np.pi)\n",
    "angle_L_hip, angle_R_hip     = angle_L_hip*(180/np.pi), angle_R_hip*(180/np.pi)\n",
    "angle_L_foot, angle_R_foot   = angle_L_foot*(180/np.pi), angle_R_foot*(180/np.pi)\n",
    "angle_Pelvis  = angle_Pelvis * (180/np.pi)\n",
    "# Create a pandas df with angles\n",
    "angs = np.hstack([angle_Pelvis, angle_L_foot, angle_R_foot, \n",
    "                  angle_L_hip, angle_R_hip, angle_L_knee, angle_R_knee, \n",
    "                  angle_L_ankle, angle_R_ankle])\n",
    "angles = pd.DataFrame(data=angs, columns=joints_lbls)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb8be29c-b4bb-4447-9ed6-0c3a755585ba",
   "metadata": {},
   "source": [
    "Function begins here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d385daf-b5a8-4e95-98c5-d065551a1589",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Determine functional measures and gait type (walk vs run)\n",
    "# % movement speed comes from the A/P position time history of a heel marker\n",
    "# % so we first need to identify a heel marker\n",
    "# LEFT SIDE\n",
    "# Determine functional measures and gait type (walk vs run) movement speed comes \n",
    "# from the A/P position time history of a heel marker so we first need to identify \n",
    "# a heel marker.\n",
    "\n",
    "# % Combine 3 of the foot markers into one matrix (ignore the created fourth)\n",
    "L_foot = neutral[['L_foot_1_X', 'L_foot_1_Y', 'L_foot_1_Z',\n",
    "              'L_foot_2_X', 'L_foot_2_Y', 'L_foot_2_Z',\n",
    "              'L_foot_3_X', 'L_foot_3_Y', 'L_foot_3_Z']].values.reshape((3,3))\n",
    "# sort the markers from left to right\n",
    "i_lf   = list(L_foot[:, 0].argsort())\n",
    "L_foot = L_foot[L_foot[:, 0].argsort()]\n",
    "\n",
    "# find the lower of the two medial markers\n",
    "if L_foot[1,1] < L_foot[2,1]:\n",
    "    L_marker = 'L_foot_' + str(i_lf[1]+1)\n",
    "    L_heel =  gait.filter(like=L_marker).values\n",
    "else:\n",
    "    L_marker = 'L_foot_' + str(i_lf[2]+1)\n",
    "    L_heel =  gait.filter(like=L_marker).values\n",
    "\n",
    "# Find peaks location. Signal flipped because of X-axis convention difference.\n",
    "locs0 = detect_peaks(np.diff(L_heel[:,2]), mpd=np.round(0.5*hz), \n",
    "                    mph=0, show=False)\n",
    "pks = np.diff(L_heel[:,2])[locs0]\n",
    "\n",
    "locs = detect_peaks(-np.diff(L_heel[:,2]), mpd=np.round(0.5*hz), \n",
    "                    mph=0, show=False)\n",
    "\n",
    "# Gait velocity and cadence\n",
    "vel    = hz*np.median(pks)/1000; # gait speed\n",
    "stRate = 60/(np.median(np.diff(locs))/hz); # cadence\n",
    "#print('Gait velocity is '+str(vel)+' m/s')\n",
    "#print('Stride rate is '+str(stRate)+' strides/min')\n",
    "\n",
    "#%% RIGHT SIDE\n",
    "# % Combine 3 of the foot markers into one matrix (ignore the created fourth)\n",
    "R_foot = neutral[['R_foot_1_X', 'R_foot_1_Y', 'R_foot_1_Z',\n",
    "              'R_foot_2_X', 'R_foot_2_Y', 'R_foot_2_Z',\n",
    "              'R_foot_3_X', 'R_foot_3_Y', 'R_foot_3_Z']].values.reshape((3,3))\n",
    "# sort the markers from left to right\n",
    "i_rf   = list(R_foot[:, 0].argsort())\n",
    "R_foot = R_foot[R_foot[:, 0].argsort()]\n",
    "\n",
    "# find the lower of the two medial markers\n",
    "if R_foot[0,1] < R_foot[1,1]:\n",
    "    R_marker = 'R_foot_' + str(i_rf[0]+1)\n",
    "    R_heel =  gait.filter(like=R_marker).values\n",
    "else:\n",
    "    R_marker = 'R_foot_' + str(i_rf[1]+1)\n",
    "    R_heel =  gait.filter(like=R_marker).values\n",
    "\n",
    "# Linear discriminant analysis\n",
    "# Import training dataset\n",
    "gaitClass = pd.read_csv(os.path.join(r'../data', 'LDA_out.txt'), delimiter='\\t', \n",
    "                        header=None, names=['Category','Speed','Cadence'], usecols=[0,1,2])\n",
    "# Replace numerical by categorical\n",
    "gaitClass['Category'] = gaitClass['Category'].replace(1, 'walk')\n",
    "gaitClass['Category'] = gaitClass['Category'].replace(2, 'run')\n",
    "\n",
    "# Input to the model\n",
    "X = gaitClass[['Speed','Cadence']].values # training data\n",
    "y = gaitClass['Category'].values.tolist() # testing data\n",
    "model = LinearDiscriminantAnalysis()# define model\n",
    "model.fit(X, y) # Model fit\n",
    "\n",
    "# make a prediction\n",
    "label = model.predict(np.array([vel,stRate]).reshape((1,2)))[0]\n",
    "#print('Gait category is '+label)\n",
    "\n",
    "# Load PCA output from mat file\n",
    "# % event_data is a .mat file containing 'coeff' which is the coefficients\n",
    "# % from the pre-trained PCA and 'p' which is the list of coefficients of the\n",
    "# % linear polynomial relating PCA scores with touchdown timing relative to\n",
    "# % the foot acceleration peak.\n",
    "event_data_TD = spio.loadmat(os.path.join(r'../data', 'event_data_TD.mat'))\n",
    "event_data_TO = spio.loadmat(os.path.join(r'../data', 'event_data_TO.mat'))\n",
    "\n",
    "#%% Identify Touch Down and Take Off events: Gait Independent\n",
    "# % Use PCA touchdown detection based on updated Osis et al. (2014) for\n",
    "# % both walking and running.\n",
    "# % Use new PCA toeoff detection for both walking and running.\n",
    "# % evt variables are NOT rounded\n",
    "try:\n",
    "    evtLtd, evtRtd = pca_td(angles, hz, event_data_TD, label)\n",
    "    evtLto, evtRto = pca_to(angles, hz, event_data_TO, label)\n",
    "\n",
    "except Exception as e: \n",
    "    #For a small number of people, these functions return errors, or in the\n",
    "    #case of bad data... default to use FF and FB in these cases\n",
    "\n",
    "    evtRtd = []\n",
    "    evtRto = []\n",
    "\n",
    "    print('Automated event detection failed, defaulting to foot-forward foot-back')\n",
    "    print(e)\n",
    "\n",
    "## LEFT FOOT EVENTS\n",
    "# % when the feet are not tracked very well, discontinuities in the heel\n",
    "# % marker can occur causing the findpeaks to pick up additional 'peaks'\n",
    "# % for the purposes of simply identifying foot forward and foot back\n",
    "# % timing, we can over filter this signal. We do not care about the\n",
    "# % magnitude of the signal but only the timing so we can overfit as long\n",
    "# % as the filter has a zero phase shift.\n",
    "# % Note: signal is now filtered by default.  There is no advantage to not\n",
    "# % filtering, as if the signal quality is already good, then the system uses\n",
    "# % PCA event detection anyhow, and if the signal is bad, then it has to be\n",
    "# % filtered in order to get foot-forward foot-backward events.\n",
    "\n",
    "# Correct the cutoff frequency for the number of passes in the filter\n",
    "b, a = butter(2, 5/(hz/2), btype = 'low')\n",
    "# note that Python and Matlab filtfilt behaves slightly different with padding the data\n",
    "# see https://mail.python.org/pipermail/scipy-user/2014-April/035646.html\n",
    "filtered_L_heel = filtfilt(b, a, L_heel[:,2], padtype='odd')\n",
    "\n",
    "# Begin by creating a gross estimation of foot forwards and foot backs\n",
    "L_FFi = detect_peaks(-filtered_L_heel, mpd=np.round(0.35*hz),\n",
    "                     show=False)\n",
    "\n",
    "if label == 'walk':\n",
    "    # % Use peak foot flexion angle for foot back\n",
    "    # % To deal with peaks resulting from signal flipping, threshold them\n",
    "    angSig = angles['L_foot_Z'].values\n",
    "    angSig[np.abs(angSig) > 90] = np.NaN\n",
    "    L_FBi = detect_peaks(-angSig, mpd=np.round(0.7*hz),\n",
    "                     mph=20, show=False)\n",
    "else:\n",
    "    # Use rearmost position of heel marker for foot back\n",
    "    L_FBi = detect_peaks(filtered_L_heel, mpd=np.round(0.35*hz),\n",
    "                     show=False)\n",
    "\n",
    "# %Uncomment block below to enable more aggressive quality control of data\n",
    "\n",
    "# if (np.nanpercentile(np.abs(angles['foot_Z'].values), 90) > 120) & vel < 4\n",
    "#     print('Right ankle values outside of expected ranges, please ensure your shoe markers are properly placed and redo your collection')\n",
    "#     sys.exit()\n",
    "\n",
    "# Remove any leading FB\n",
    "L_FBi = L_FBi[L_FBi>L_FFi[0]]\n",
    "\n",
    "## find largest chunk of continuous data\n",
    "\n",
    "#We want to check before and after that there is sufficient data for analysis\n",
    "\n",
    "if (L_FFi.shape[0] < 2) or (L_FBi.shape[0] < 2):\n",
    "    print('Automated event detection unable to pull adequate number of strides for analysis. Please redo your data collection.')\n",
    "    sys.exit()\n",
    "\n",
    "# Call Matlab function LARGEST_BLOCK.m from Python\n",
    "eng = matlab.engine.start_matlab() # start Matlab engine\n",
    "eng.cd(r'../functions', nargout=0) # set path for functions dir\n",
    "\n",
    "\n",
    "L_FFi, L_FBi, L_block_start, block_end = eng.largest_block(matlab.double(list(L_FFi)), \n",
    "                                                             matlab.double(list(L_FBi)), nargout=4)\n",
    "\n",
    "L_FFi = np.array(L_FFi).flatten().astype(int)\n",
    "L_FBi = np.array(L_FBi).flatten().astype(int)\n",
    "\n",
    "if (L_FFi.shape[0] < 2) or (L_FBi.shape[0] < 2):\n",
    "    print('Automated event detection unable to pull adequate number of strides for analysis. Please redo your data collection.')\n",
    "    sys.exit()\n",
    "\n",
    "# TOUCHDOWN\n",
    "# evtLtd from above\n",
    "\n",
    "# SELECT SEQUENTIAL STEPS\n",
    "# create an ordered set of sequential steps using FFi as guide\n",
    "closest = np.abs(np.repeat(L_FFi[:,np.newaxis], evtLtd.shape[0], axis=1)-np.repeat(evtLtd[:,np.newaxis].T, L_FFi.shape[0], axis=0))\n",
    "\n",
    "mindist, minx = np.nanmin(closest, axis=0), np.nanargmin(closest, axis=0)\n",
    "\n",
    "for i in np.unique(minx).astype(int):\n",
    "    if np.sum(np.isin(i,minx)) > 1:\n",
    "        mindist = mindist[minx!=i]\n",
    "        evtLtd  = evtLtd[minx!=i]\n",
    "        minx    = minx[minx!=i]\n",
    "\n",
    "# Parameter based on the typical frame adjustments observed in 300\n",
    "# datasets\n",
    "if label=='run':\n",
    "    maxadj = 0.05*hz\n",
    "else:\n",
    "    maxadj = 0.10*hz\n",
    "\n",
    "# Preallocate\n",
    "L_TD = np.empty(L_FFi.shape[0]) * np.NaN\n",
    "evFltd = np.zeros(L_FFi.shape[0])\n",
    "\n",
    "# Here we replace FF indices with indices from evt where criteria are\n",
    "# met... the default is to use FF\n",
    "for i in range(L_FFi.shape[0]):\n",
    "    try:\n",
    "        if i > np.max(minx):\n",
    "            break\n",
    "        elif np.isin(i,minx) and (mindist[minx==i] < maxadj).any():\n",
    "            #Replace with evtLtd since its more accurate\n",
    "            L_TD[i] = evtLtd[minx==i][0]\n",
    "            evFltd[i] = 1\n",
    "        else:\n",
    "            #Use FFi since it is more robust\n",
    "            L_TD[i] = L_FFi[i]\n",
    "\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        L_TD[i] = L_FFi[i]\n",
    "\n",
    "# %% TAKEOFF\n",
    "\n",
    "# % evtLto from above\n",
    "\n",
    "# % SELECT SEQUENTIAL STEPS\n",
    "\n",
    "# % Now create an ordered set of sequential steps using FBi as guide\n",
    "closest = np.abs(np.repeat(L_FBi[:,np.newaxis], evtLto.shape[0], axis=1)-np.repeat(evtLto[:,np.newaxis].T, L_FBi.shape[0], axis=0))\n",
    "\n",
    "mindist, minx = np.nanmin(closest, axis=0), np.nanargmin(closest, axis=0)\n",
    "for i in np.unique(minx).astype(int):\n",
    "    if np.sum(np.isin(i,minx)) > 1:\n",
    "        mindist = mindist[minx!=i]\n",
    "        evtLtd  = evtLtd[minx!=i]\n",
    "        minx    = minx[minx!=i]\n",
    "\n",
    "# Parameter based on the frame adjustment observed from 300 datasets\n",
    "maxadj = 0.15*hz\n",
    "\n",
    "# Preallocate\n",
    "L_TO = np.empty(L_FBi.shape[0]) * np.NaN\n",
    "evFlto = np.zeros(L_FBi.shape[0])\n",
    "\n",
    "# Here we replace FB indices with TO from PCA default is to use FB\n",
    "for i in range(L_FBi.shape[0]):\n",
    "    try:\n",
    "        if i > np.max(minx):\n",
    "            break\n",
    "        elif np.isin(i,minx) and (mindist[minx==i] < maxadj).any():\n",
    "            #Replace with evtLto since its more accurate\n",
    "            L_TO[i] = evtLto[minx==i][0]\n",
    "            evFlto[i] = 1\n",
    "        else:\n",
    "            #Use FFi since it is more robust\n",
    "            L_TO[i] = L_FBi[i]\n",
    "\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        L_TO[i] = L_FBi[i]\n",
    "\n",
    "# Finally we round to get final indices\n",
    "L_TD = L_TD.round()\n",
    "L_TO = L_TO.round()\n",
    "\n",
    "\n",
    "# %% RIGHT FOOT EVENTS\n",
    "# % the same steps we just took for the left side\n",
    "\n",
    "# % Begin by creating a gross estimation of foot forwards and foot backs\n",
    "# Correct the cutoff frequency for the number of passes in the filter\n",
    "b, a = butter(2, 5/(hz/2), btype = 'low')\n",
    "# note that Python and Matlab filtfilt behaves slightly different with padding the data\n",
    "# see https://mail.python.org/pipermail/scipy-user/2014-April/035646.html\n",
    "filtered_R_heel = filtfilt(b, a, R_heel[:,2], padtype='odd')\n",
    "\n",
    "# Begin by creating a gross estimation of foot forwards and foot backs\n",
    "R_FFi = detect_peaks(-filtered_R_heel, mpd=np.round(0.35*hz),\n",
    "                     show=False)\n",
    "\n",
    "if label == 'walk':\n",
    "    # % Use peak foot flexion angle for foot back\n",
    "    # % To deal with peaks resulting from signal flipping, threshold them\n",
    "    angSig = angles['R_foot_Z'].values\n",
    "    angSig[np.abs(angSig) > 90] = np.NaN\n",
    "    R_FBi = detect_peaks(-angSig, mpd=np.round(0.7*hz),\n",
    "                     mph=20, show=False)\n",
    "else:\n",
    "    # Use rearmost position of heel marker for foot back\n",
    "    R_FBi = detect_peaks(filtered_R_heel, mpd=np.round(0.35*hz),\n",
    "                     show=False)\n",
    "\n",
    "# %Uncomment block below to enable more aggressive quality control of data\n",
    "\n",
    "# if (np.nanpercentile(np.abs(angles['R_foot_Z'].values), 90) > 120) & vel < 4\n",
    "#     print('Right ankle values outside of expected ranges, please ensure your shoe markers are properly placed and redo your collection')\n",
    "#     sys.exit()\n",
    "\n",
    "# Remove any leading FB\n",
    "R_FFi = R_FFi[R_FFi>L_FFi[0]]\n",
    "R_FBi = R_FBi[R_FBi>R_FFi[0]]\n",
    "\n",
    "## find largest chunk of continuous data\n",
    "\n",
    "#We want to check before and after that there is sufficient data for analysis\n",
    "\n",
    "if (R_FFi.shape[0] < 2) or (R_FBi.shape[0] < 2):\n",
    "    print('Automated event detection unable to pull adequate number of strides for analysis. Please redo your data collection.')\n",
    "    sys.exit()\n",
    "\n",
    "\n",
    "# LARGEST_BLOCK\n",
    "R_FFi, R_FBi, R_block_start, R_block_end = eng.largest_block(matlab.double(list(R_FFi)), \n",
    "                                                             matlab.double(list(R_FBi)), nargout=4)\n",
    "\n",
    "R_FFi = np.array(R_FFi).flatten().astype(int)\n",
    "R_FBi = np.array(R_FBi).flatten().astype(int)\n",
    "\n",
    "if (R_FFi.shape[0] < 2) or (R_FBi.shape[0] < 2):\n",
    "    print('Automated event detection unable to pull adequate number of strides for analysis. Please redo your data collection.')\n",
    "    sys.exit()\n",
    "\n",
    "# %In rare instances a the index will be in incorrect order run below again\n",
    "# %in case\n",
    "\n",
    "# % Remove any leading FF and FB\n",
    "R_FFi = R_FFi[R_FFi>L_FFi[0]]\n",
    "R_FBi = R_FBi[R_FBi>R_FFi[0]]\n",
    "\n",
    "# TOUCHDOWN\n",
    "# evtRtd from above\n",
    "\n",
    "# SELECT SEQUENTIAL STEPS\n",
    "# create an ordered set of sequential steps using FFi as guide\n",
    "closest = np.abs(np.repeat(R_FFi[:,np.newaxis], evtRtd.shape[0], axis=1)-np.repeat(evtRtd[:,np.newaxis].T, R_FFi.shape[0], axis=0))\n",
    "\n",
    "mindist, minx = np.nanmin(closest, axis=0), np.nanargmin(closest, axis=0)\n",
    "\n",
    "for i in np.unique(minx).astype(int):\n",
    "    if np.sum(np.isin(i,minx)) > 1:\n",
    "        mindist = mindist[minx!=i]\n",
    "        evtLtd  = evtLtd[minx!=i]\n",
    "        minx    = minx[minx!=i]\n",
    "\n",
    "# Parameter based on the typical frame adjustments observed in 300\n",
    "# datasets\n",
    "if label=='run':\n",
    "    maxadj = 0.05*hz\n",
    "else:\n",
    "    maxadj = 0.10*hz\n",
    "\n",
    "# Preallocate\n",
    "R_TD = np.empty(R_FFi.shape[0]) * np.NaN\n",
    "evFrtd = np.zeros(R_FFi.shape[0])\n",
    "\n",
    "# Here we replace FF indices with indices from evt where criteria are\n",
    "# met... the default is to use FF\n",
    "for i in range(R_FFi.shape[0]):\n",
    "    try:\n",
    "        if i > np.max(minx):\n",
    "            break\n",
    "        elif np.isin(i,minx) and (mindist[minx==i] < maxadj).any():\n",
    "            #Replace with evtRtd since its more accurate\n",
    "            R_TD[i] = evtRtd[minx==i][0]\n",
    "            evFrtd[i] = 1\n",
    "        else:\n",
    "            #Use FFi since it is more robust\n",
    "            R_TD[i] = R_FFi[i]\n",
    "\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        R_TD[i] = R_FFi[i]\n",
    "\n",
    "\n",
    "# %% TAKEOFF\n",
    "\n",
    "# % evtRto from above\n",
    "\n",
    "# % SELECT SEQUENTIAL STEPS\n",
    "\n",
    "# % Now create an ordered set of sequential steps using FBi as guide\n",
    "closest = np.abs(np.repeat(R_FBi[:,np.newaxis], evtRto.shape[0], axis=1)-np.repeat(evtRto[:,np.newaxis].T, R_FBi.shape[0], axis=0))\n",
    "\n",
    "mindist, minx = np.nanmin(closest, axis=0), np.nanargmin(closest, axis=0)\n",
    "for i in np.unique(minx).astype(int):\n",
    "    if np.sum(np.isin(i,minx)) > 1:\n",
    "        mindist = mindist[minx!=i]\n",
    "        evtLtd  = evtLtd[minx!=i]\n",
    "        minx    = minx[minx!=i]\n",
    "\n",
    "# Parameter based on the frame adjustment observed from 300 datasets\n",
    "maxadj = 0.15*hz\n",
    "\n",
    "# Preallocate\n",
    "R_TO = np.empty(R_FBi.shape[0]) * np.NaN\n",
    "evFrto = np.zeros(R_FBi.shape[0])\n",
    "\n",
    "# Here we replace FB indices with TO from PCA default is to use FB\n",
    "for i in range(R_FBi.shape[0]):\n",
    "    try:\n",
    "        if i > np.max(minx):\n",
    "            break\n",
    "        elif np.isin(i,minx) and (mindist[minx==i] < maxadj).any():\n",
    "            #Replace with evtLto since its more accurate\n",
    "            R_TO[i] = evtRto[minx==i][0]\n",
    "            evFrto[i] = np.float64(1)\n",
    "        else:\n",
    "            #Use FFi since it is more robust\n",
    "            R_TO[i] = R_FBi[i]\n",
    "\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        R_TO[i] = R_FBi[i]\n",
    "\n",
    "# Finally we round to get final indices\n",
    "R_TD = R_TD.round()\n",
    "R_TO = R_TO.round()\n",
    "\n",
    "# %% if largest chunk of continuous data not at beginning, chop both right and left so they match\n",
    "\n",
    "\n",
    "# %index must begin with left touchdown and end with right toe\n",
    "# %off\n",
    "\n",
    "\n",
    "if R_block_start < L_block_start:\n",
    "    #remove all right indices that occur before the first left touchdown\n",
    "\n",
    "    R_TO = R_TO[(R_TD < L_block_start)!=1]\n",
    "    R_TD = R_TD[(R_TD < L_block_start)!=1]\n",
    "\n",
    "flag = 0\n",
    "\n",
    "if L_block_start < R_block_start:\n",
    "    #remove left touchdowns more than one touchdown before the first right touchdown\n",
    "    cut_inds = (L_TD<R_block_start)==1\n",
    "    cut_inds.astype(int)\n",
    "    #this loop ensures the first index will be a left touchdown\n",
    "    for i in range(cut_inds.shape[0]):\n",
    "        if (cut_inds[i]==1) and (cut_inds[i+1]==0) and flag==0:\n",
    "            cut_inds[i] = 0\n",
    "            flag = 1\n",
    "\n",
    "    L_TD = np.delete(L_TD, cut_inds)\n",
    "    L_TO = np.delete(L_TO, cut_inds)\n",
    "\n",
    "\n",
    "# create an events matrix\n",
    "# Remove trailing nans that may have crept in\n",
    "evFltd = evFltd[~np.isnan(L_TD)]\n",
    "evFlto = evFlto[~np.isnan(L_TO)]\n",
    "evFrtd = evFrtd[~np.isnan(R_TD)]\n",
    "evFrto = evFrto[~np.isnan(R_TO)]\n",
    "\n",
    "L_TD = L_TD[~np.isnan(L_TD)]\n",
    "L_TO = L_TO[~np.isnan(L_TO)]\n",
    "R_TD = R_TD[~np.isnan(R_TD)]\n",
    "R_TO = R_TO[~np.isnan(R_TO)]\n",
    "\n",
    "# Find the closest ordered pairs of L_TO and R_TD to synchronize steps\n",
    "closest = np.abs(np.repeat(R_TD[:,np.newaxis], L_TO.shape[0], axis=1)-np.repeat(L_TO[:,np.newaxis].T, R_TD.shape[0], axis=0))\n",
    "\n",
    "minx = np.nanargmin(closest,axis=0)\n",
    "\n",
    "#Truncate right stances to match up with left\n",
    "evFrtd = evFrtd[np.unique(minx)]\n",
    "R_TD = R_TD[np.unique(minx)]\n",
    "\n",
    "\n",
    "testlength = np.min([L_TO.shape[0], R_TD.shape[0]])\n",
    "if np.median(L_TO[:testlength]-R_TD[:testlength]) < 0:#Then there is a flight phase\n",
    "    #Find the closest ordered pairs of R_TD and R_TO to synchronize steps\n",
    "    closest = np.abs(np.repeat(R_TO[:,np.newaxis], R_TD.shape[0], axis=1)-np.repeat(R_TD[:,np.newaxis].T, R_TO.shape[0], axis=0))\n",
    "    minx = np.nanargmin(closest,axis=0)\n",
    "\n",
    "else: # There is no flight phase i.e. grounded running or walking\n",
    "    #Find the closest ordered pairs of R_TO and L_TD to synchronize steps\n",
    "    tmp = L_TD[1:]\n",
    "    closest = np.abs(np.repeat(R_TO[:,np.newaxis], tmp.shape[0], \n",
    "                               axis=1)-np.repeat(tmp[:,np.newaxis].T, R_TO.shape[0], axis=0))\n",
    "    minx = np.nanargmin(closest,axis=0)\n",
    "\n",
    "evFrto = evFrto[np.unique(minx)]\n",
    "R_TO = R_TO[np.unique(minx)]\n",
    "\n",
    "events = [L_TD.shape[0], L_TO.shape[0], R_TD.shape[0], R_TO.shape[0]]\n",
    "\n",
    "# Chop everything to the same length\n",
    "L_TD = L_TD[:min(events)]\n",
    "L_TO = L_TO[:min(events)]\n",
    "R_TD = R_TD[:min(events)]\n",
    "R_TO = R_TO[:min(events)]\n",
    "\n",
    "evFltd = evFltd[:min(events)]\n",
    "evFlto = evFlto[:min(events)]\n",
    "evFrtd = evFrtd[:min(events)]\n",
    "evFrto = evFrto[:min(events)]\n",
    "\n",
    "# Very rarely, these will wind up empty and assignment doesn't work\n",
    "events = np.empty(shape=(L_TD.shape[0],4)) * np.NaN\n",
    "events[:,0]=L_TD\n",
    "events[:,1]=L_TO\n",
    "events[:,2]=R_TD\n",
    "events[:,3]=R_TO\n",
    "# Very rarely, these will wind up empty and assignment doesn't work\n",
    "eventsflag = np.empty(shape=(evFltd.shape[0],4)) * np.NaN\n",
    "eventsflag[:,0]=evFltd\n",
    "eventsflag[:,1]=evFlto\n",
    "eventsflag[:,2]=evFrtd\n",
    "eventsflag[:,3]=evFrto\n",
    "\n",
    "# Remove first row since these will very often be reliant on FF and FB measures\n",
    "if events.shape[0] > 1:\n",
    "    events = np.delete(events,0,axis=0)\n",
    "    eventsflag = np.delete(eventsflag,0,axis=0)\n",
    "\n",
    "# %% Occasionally, one stance will drop out, and data becomes\n",
    "# % discontinuous...this fix alleviates this by trimming data to largest\n",
    "# % continuous block\n",
    "try:\n",
    "    cont = np.array([events[1:,0]>events[:-1,1],events[1:,2]>events[:-1,3]])\n",
    "    cont = np.hstack((np.zeros((2,1)),cont,np.zeros((2,1)))).T\n",
    "    F = np.where(np.any(cont==0, axis=1))\n",
    "    F = np.asarray(F).flatten()\n",
    "    D = np.diff(F)-2\n",
    "    M, L = np.max(D), np.argmax(D)\n",
    "    events = events[F[L]:F[L]+M+1,:]\n",
    "    eventsflag = eventsflag[F[L]:F[L]+M+1,:]\n",
    "except Exception as e:\n",
    "    print('Could not obtain a continuous block of events')\n",
    "    events = []\n",
    "    eventsflag = []\n",
    "    print(e)\n",
    "\n",
    "# Worst-case... return to foot forward, foot back detection\n",
    "if events.shape[0] < 5:\n",
    "    print('Automated event detection failed, defaulting to foot-forward foot-back')\n",
    "    nevents = [L_FFi.shape[0], L_FBi.shape[0], R_FFi.shape[0], R_FBi.shape[0]]\n",
    "\n",
    "    # Chop everything to the same length\n",
    "    L_FFi = L_FFi[:min(nevents)]\n",
    "    L_FBi = L_FBi[:min(nevents)]\n",
    "    R_FFi = R_FFi[:min(nevents)]\n",
    "    R_FBi = R_FBi[:min(nevents)]\n",
    "\n",
    "    events = np.empty(shape=(min(nevents),4)) * np.NaN\n",
    "    events[:,0] = L_FFi\n",
    "    events[:,1] = L_FBi\n",
    "    events[:,2] = R_FFi\n",
    "    events[:,3] = R_FBi\n",
    "\n",
    "# Pull event columns from events so everything is consistent\n",
    "L_TD = events[:,0]\n",
    "L_TO = events[:,1]\n",
    "R_TD = events[:,2]\n",
    "R_TO = events[:,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa813db9-2bac-421b-b044-f2fa85e51e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "L_TDm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfae31c0-0cb0-4f36-b871-618c10b4a582",
   "metadata": {},
   "outputs": [],
   "source": [
    "L_TO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e103ca-1219-4d90-9cfb-0d4185887609",
   "metadata": {},
   "outputs": [],
   "source": [
    "L_TOm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ff14f38-c885-4cf7-a6c2-2dcc4efb08a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "R_TD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d730a89-7229-4e8f-a53c-d0cc7c7f90a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "R_TDm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c5e8573-71d8-4402-9a5a-4684de4090ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80b55360-951a-4e0c-9e22-28c5829b0a89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b35118ca-e8fa-4600-85f8-b09e808ce1d4",
   "metadata": {},
   "source": [
    "## Compare outputs between gait_steps.m and gait_steps.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08e00a5f-2607-4493-8b92-cf7678e168b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Invoking function to calculate angles\n",
    "#angle_L_ankle, angle_R_ankle, angle_L_knee, angle_R_knee, angle_L_hip, angle_R_hip, angle_L_foot, angle_R_foot, angle_Pelvis = gait_kinematics(joints, neutral, gait, data_RIC['hz_r'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df5bcad3-61cc-4c65-ad3c-15931c439907",
   "metadata": {},
   "outputs": [],
   "source": [
    "'L_ankle','R_ankle','L_knee','R_knee','L_hip','R_hip','L_foot','R_foot','pelvis'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96b585fb-71ed-40d3-a81d-b98874beca00",
   "metadata": {},
   "outputs": [],
   "source": [
    "angles_dict = dict()\n",
    "angles_dict['L_ankle'] = angle_L_ankle\n",
    "angles_dict['R_ankle'] = angle_R_ankle\n",
    "angles_dict['L_knee']  = angle_L_knee\n",
    "angles_dict['R_knee']  = angle_R_knee\n",
    "angles_dict['L_hip']   = angle_L_hip\n",
    "angles_dict['R_hip']   = angle_R_hip\n",
    "angles_dict['L_foot']  = angle_L_foot\n",
    "angles_dict['R_foot']  = angle_R_foot\n",
    "angles_dict['pelvis']  = angle_Pelvis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f73e21ac-91f1-49ab-8169-1408e094b38d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_RIC['hz_r']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8c98d09-682a-4ff9-927e-373444885fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "matlab.double(float(data_RIC['hz_r']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ac7d3e-e23f-4abe-98bb-04e33f47070d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call Matlab function gait_steps.m from Python\n",
    "norm_ang, norm_vel, events, event, dvs, vel, eventsflag, label = eng.gait_steps(data_RIC['neutral'], \n",
    "                                                        data_RIC['running'], \n",
    "                                                        angles_dict, angles_dict,\n",
    "                                                        data_RIC['hz_r'],0,\n",
    "                                                        nargout=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e40d2fdf-a059-410a-9223-60084830012f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b93c8228-0994-4489-bc5e-adb709b1b672",
   "metadata": {},
   "outputs": [],
   "source": [
    "#[norm_ang,norm_vel,events,event,DISCRETE_VARIABLES,speedoutput,eventsflag,label] = gait_steps(neutral,dynamic,angles,velocities,hz,plots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be63984f-70e1-4e4a-bf8c-212366f96cee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd770c75-6096-4edf-9814-f1d68f665000",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e3f22da-c7d8-4271-b7f6-8be17892eb2f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7013eb8-83ef-42af-8d4e-32526421ec2f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2cad6c8-945b-406f-9bf4-eb2cd47e5909",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
